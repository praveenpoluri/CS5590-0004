{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "L_6_Encrypted_Deep_Learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveenpoluri/CS5590-0004/blob/master/icp8/L_6_Encrypted_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us4odjHbOlZ2",
        "colab_type": "text"
      },
      "source": [
        "# Section: Encrypted Deep Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O4L5MhQOlbP",
        "colab_type": "text"
      },
      "source": [
        "# Encrypted Computations in PySyft"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSWgkSn8OlbP",
        "colab_type": "code",
        "outputId": "4a23f5bc-0523-4545-9f8e-03a20a2aa7b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import syft as sy\n",
        "import torch as th\n",
        "from torch import nn, optim\n",
        "\n",
        "hook = sy.TorchHook(th)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0711 21:44:38.286935 140259911964544 hook.py:98] Torch was already hooked... skipping hooking process\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTH4ckr7OlbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bob = sy.VirtualWorker(hook, id=\"bob\").add_worker(sy.local_worker)\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\").add_worker(sy.local_worker)\n",
        "secure_worker = sy.VirtualWorker(hook, id=\"secure_worker\").add_worker(sy.local_worker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kd7wOFwOlbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = th.tensor([1,2,3,4])\n",
        "y = th.tensor([2,-1,1,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOG4U2EFOlbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we assigned one of the parties, secure_worker, to generate the random numbers \n",
        "# we have trust that the secure_worker, one of the parties, does not know Alice or Bob (they also do not know each other)\n",
        "# use the parameter crypto_provider to assign on of the parties\n",
        "\n",
        "x = x.share(bob, alice, crypto_provider=secure_worker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgG_yntKOlbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = y.share(bob, alice, crypto_provider=secure_worker) # notice the number of the parties where the secrete is shared"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkrinOBuTOR_",
        "colab_type": "code",
        "outputId": "f221b2fe-2ef8-4d46-9910-a810ec712abf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{5832710301: tensor([1942124677794672934, 1386511262076046253, 1864651451166692784,\n",
              "         2923358307548933517]),\n",
              " 37155951963: tensor([1024298226974157009, 3757621307906408434, 3212090408686283635,\n",
              "          585039451028585162])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlDB43N_S80s",
        "colab_type": "text"
      },
      "source": [
        "We have shared two secretes with three parties. Let's try some computations remotely on these secretes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kgrq-s7Olba",
        "colab_type": "code",
        "outputId": "1a740a1b-c6c3-4596-d813-516b2da02b85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# adding secretes on remote machines\n",
        "z = x + y\n",
        "z.get() # returns and decodes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 1, 4, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyMGTYssOlbc",
        "colab_type": "code",
        "outputId": "b96ef21e-77c8-40da-f579-7fe5f717c02a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# subtracting secretes on remote machines\n",
        "\n",
        "z = x - y\n",
        "z.get()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1,  3,  2,  4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjpjZ0UOOlbe",
        "colab_type": "code",
        "outputId": "da3cf9ca-07e1-4b47-b9a1-2109baf7e2aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# multiplying secretes on remote machines\n",
        "\n",
        "z = x * y\n",
        "z.get()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2, -2,  3,  0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv3PisuLOlbg",
        "colab_type": "code",
        "outputId": "b0c08b26-3276-4d64-eacf-624b297bff44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# boolean operations on remote machines\n",
        "z = x > y\n",
        "z.get()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBRXxrrxOlbj",
        "colab_type": "code",
        "outputId": "a845b104-f6e4-454d-c603-44f936eb36d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "z = x < y\n",
        "z.get()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4mYZ1iKOlbl",
        "colab_type": "code",
        "outputId": "b9a6ead9-40fe-475d-fc06-ad990cfaba53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "z = x == y\n",
        "z.get()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D43N_iKAOlbq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# double check that your implementation is using the fix_precision() function when dealing with float values\n",
        "# reverse this function using the float_precision() function\n",
        "\n",
        "x = th.tensor([1.2, 2.2, 3.2, 4.2])\n",
        "y = th.tensor([2.1, -1.1, 1.1, 0.1])\n",
        "\n",
        "x = x.fix_precision().share(bob, alice, crypto_provider=secure_worker)\n",
        "y = y.fix_precision().share(bob, alice, crypto_provider=secure_worker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZrB_aACOlbs",
        "colab_type": "code",
        "outputId": "0a358008-e612-4ce5-8082-4fa86bd58228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "z = x + y\n",
        "z.get().float_precision()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3.3000, 1.1000, 4.3000, 4.3000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G0NEPrmOlbu",
        "colab_type": "code",
        "outputId": "dd8f775d-5caf-4a66-fb52-13b54d38872a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "z = x - y\n",
        "z.get().float_precision()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.9000,  3.3000,  2.1000,  4.1000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3klZfOwNOlby",
        "colab_type": "code",
        "outputId": "7db4f067-ffb3-434b-a4c8-a2d680d4923a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "z = x * y\n",
        "z.get().float_precision()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2.5200, -2.4200,  3.5200,  0.4200])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FL-iG723Olb1",
        "colab_type": "code",
        "outputId": "a5fe61fa-a6c0-4e3a-d8f8-72f1bdb351c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "z = x > y\n",
        "z.get().float_precision()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxCOrhedOlb4",
        "colab_type": "code",
        "outputId": "74fef787-5870-4407-ec9e-e10550596168",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "z = x < y\n",
        "z.get().float_precision()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTlmw71SOlb7",
        "colab_type": "code",
        "outputId": "56822b98-7915-44e5-919f-d53f1023a0a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "z = x == x\n",
        "z.get().float_precision()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIk8x_AQOlcV",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Encrypted Deep Learning in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFZYwgwUOlcV",
        "colab_type": "text"
      },
      "source": [
        "### Build your algorithms and Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sop2iTp9OlcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# A Toy Dataset\n",
        "data = th.tensor([[0,0],[0,1],[1,0],[1,1.]], requires_grad=True)\n",
        "target = th.tensor([[0],[0],[1],[1.]], requires_grad=True)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 20)\n",
        "        self.fc2 = nn.Linear(20, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "def train():\n",
        "    # Training Logic\n",
        "    opt = optim.SGD(params=model.parameters(), lr=0.1)\n",
        "    for iter in range(20):\n",
        "\n",
        "        # 1) erase previous gradients (if they exist)\n",
        "        opt.zero_grad()\n",
        "\n",
        "        # 2) make a prediction\n",
        "        pred = model(data)\n",
        "\n",
        "        # 3) calculate how much we missed\n",
        "        loss = ((pred - target)**2).sum()\n",
        "\n",
        "        # 4) figure out which weights caused us to miss\n",
        "        loss.backward()\n",
        "\n",
        "        # 5) change those weights\n",
        "        opt.step()\n",
        "\n",
        "        # 6) print our progress\n",
        "        print(loss.data)\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo_89R2r1NJA",
        "colab_type": "code",
        "outputId": "14f65750-df46-42d9-bd8b-71d517d8d833",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "model = Net()\n",
        "\n",
        "#train the model\n",
        "train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.1571)\n",
            "tensor(12.9535)\n",
            "tensor(21.6353)\n",
            "tensor(1.1473)\n",
            "tensor(0.9781)\n",
            "tensor(0.9570)\n",
            "tensor(0.9398)\n",
            "tensor(0.9207)\n",
            "tensor(0.8990)\n",
            "tensor(0.8741)\n",
            "tensor(0.8455)\n",
            "tensor(0.8128)\n",
            "tensor(0.7757)\n",
            "tensor(0.7359)\n",
            "tensor(0.6929)\n",
            "tensor(0.6448)\n",
            "tensor(0.5935)\n",
            "tensor(0.5378)\n",
            "tensor(0.4791)\n",
            "tensor(0.4152)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSLb2kraOlcY",
        "colab_type": "code",
        "outputId": "71144371-8250-4f80-a2cb-cf462284b8ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# run predictions\n",
        "model(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1881],\n",
              "        [0.4219],\n",
              "        [0.8541],\n",
              "        [0.6796]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et_uu6I4OlcZ",
        "colab_type": "text"
      },
      "source": [
        "## Encrypt the Model and Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXJRwKyKOlca",
        "colab_type": "code",
        "outputId": "ab18971e-f0bd-4cbe-9b68-4f214e2499d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "encrypted_model = model.fix_precision().share(alice, bob, crypto_provider=secure_worker)\n",
        "encrypted_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (fc1): Linear(in_features=2, out_features=20, bias=True)\n",
              "  (fc2): Linear(in_features=20, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzS4Po8FOlcb",
        "colab_type": "code",
        "outputId": "d1de19a0-1db8-47e6-d8ef-ab5c5a2c7828",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "list(encrypted_model.parameters())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " Parameter>AutogradTensor>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
              " \t-> (Wrapper)>[PointerTensor | me:5747582235 -> bob:22955187796]\n",
              " \t-> (Wrapper)>[PointerTensor | me:70178304243 -> alice:68052171563]\n",
              " \t*crypto provider: secure_worker*, Parameter containing:\n",
              " Parameter>AutogradTensor>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
              " \t-> (Wrapper)>[PointerTensor | me:43107561652 -> bob:71961852178]\n",
              " \t-> (Wrapper)>[PointerTensor | me:86414278975 -> alice:68762703899]\n",
              " \t*crypto provider: secure_worker*, Parameter containing:\n",
              " Parameter>AutogradTensor>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
              " \t-> (Wrapper)>[PointerTensor | me:50688519605 -> bob:86048180237]\n",
              " \t-> (Wrapper)>[PointerTensor | me:55780423456 -> alice:63836427461]\n",
              " \t*crypto provider: secure_worker*, Parameter containing:\n",
              " Parameter>AutogradTensor>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
              " \t-> (Wrapper)>[PointerTensor | me:23107485845 -> bob:14352544615]\n",
              " \t-> (Wrapper)>[PointerTensor | me:73363989459 -> alice:38973940486]\n",
              " \t*crypto provider: secure_worker*]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9Kslrp5Olch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encrypted_data = data.fix_precision().share(alice, bob, crypto_provider=secure_worker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TArHg4_AUkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encrypted_prediction = encrypted_model(encrypted_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z_w3ryjOlck",
        "colab_type": "code",
        "outputId": "3bc36958-ec6d-4414-fd2a-a53ac180c1b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "encrypted_prediction.get().float_precision()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1870],\n",
              "        [0.4210],\n",
              "        [0.8530],\n",
              "        [0.6780]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZLsNTrBClfn",
        "colab_type": "text"
      },
      "source": [
        "# Reuse the MNIST NN from the previous classes (firs week of classes) to train the classifier with a Secure Federated learning appraoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xggxhrrlCxUM",
        "colab_type": "code",
        "outputId": "ba2b479e-0b5b-4fa9-84a4-b4732b408560",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "!pip install syft"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting syft\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/2e/16bdefc78eb089e1efa9704c33b8f76f035a30dc935bedd7cbb22f6dabaa/syft-0.1.21a1-py3-none-any.whl (219kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Collecting flask-socketio>=3.3.2 (from syft)\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/68/fe4806d3a0a5909d274367eb9b3b87262906c1515024f46c2443a36a0c82/Flask_SocketIO-4.1.0-py2.py3-none-any.whl\n",
            "Collecting lz4>=2.1.6 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl (385kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 46.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.3.0)\n",
            "Collecting websocket-client>=0.56.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 44.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.21.2)\n",
            "Collecting tf-encrypted>=0.5.4 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/ce/da9916e7e78f736894b15538b702c0b213fd5d60a7fd6e481d74033a90c0/tf_encrypted-0.5.6-py3-none-manylinux1_x86_64.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 48.7MB/s \n",
            "\u001b[?25hCollecting zstd>=1.4.0.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/27/1ea8086d37424e83ab692015cc8dd7d5e37cf791e339633a40dc828dfb74/zstd-1.4.0.0.tar.gz (450kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 48.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.1)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.0)\n",
            "Collecting websockets>=7.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/5e/2fe6afbb796c6ac5c006460b5503cd674d33706660337f2dbff10d4aa12d/websockets-8.0-cp36-cp36m-manylinux1_x86_64.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 25.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.16.4)\n",
            "Collecting msgpack>=0.6.1 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/7e/ae9e91c1bb8d846efafd1f353476e3fd7309778b582d2fb4cea4cc15b9a2/msgpack-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 42.6MB/s \n",
            "\u001b[?25hCollecting python-socketio>=2.1.0 (from flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/1b/57e860a86f2a01be86ae1dacfa0cd8c4dfbfcd4593322268b61b5a07b564/python_socketio-4.2.0-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 16.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (4.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (0.13.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (1.3.0)\n",
            "Requirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Collecting pyyaml>=5.1 (from tf-encrypted>=0.5.4->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/837fefac7475963d1eccf4aa684c23b95aa6c1d033a2c5965ccb11e22623/PyYAML-5.1.1.tar.gz (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 45.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (0.15.4)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (7.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (2.10.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (1.1.0)\n",
            "Collecting python-engineio>=3.8.0 (from python-socketio>=2.1.0->flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/b8/0fc389ca5c445051b37b17802f80bbf1b51c1e3b48b772ee608efbb90583/python_engineio-3.8.2.post1-py2.py3-none-any.whl (119kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 40.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->syft) (0.46)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.8.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.1.7)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.7.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.11.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.33.4)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=1.0.2->syft) (1.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (2.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.1.1)\n",
            "Building wheels for collected packages: zstd, pyyaml\n",
            "  Building wheel for zstd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/9a/f4/3105b5209674ac77fcca7fede95184c62a95df0196888e0e76\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/27/a1/775c62ddea7bfa62324fd1f65847ed31c55dadb6051481ba3f\n",
            "Successfully built zstd pyyaml\n",
            "Installing collected packages: python-engineio, python-socketio, flask-socketio, lz4, websocket-client, pyyaml, tf-encrypted, zstd, websockets, msgpack, syft\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: msgpack 0.5.6\n",
            "    Uninstalling msgpack-0.5.6:\n",
            "      Successfully uninstalled msgpack-0.5.6\n",
            "Successfully installed flask-socketio-4.1.0 lz4-2.1.10 msgpack-0.6.1 python-engineio-3.8.2.post1 python-socketio-4.2.0 pyyaml-5.1.1 syft-0.1.21a1 tf-encrypted-0.5.6 websocket-client-0.56.0 websockets-8.0 zstd-1.4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCzifgOVKCSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import helper"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuK2kFkkKScV",
        "colab_type": "code",
        "outputId": "cf134b61-ba74-458c-8352-24939ea59c0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "\n",
        "import syft as sy\n",
        "import torch as th\n",
        "from torch import nn, optim\n",
        "\n",
        "hook = sy.TorchHook(th)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0715 05:44:41.251134 140389860087680 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0715 05:44:41.268629 140389860087680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNgI3r0KKZJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a couple workers\n",
        "\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
        "crypto_provider = sy.VirtualWorker(hook, id=\"crypto_provider\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY9Ml0l8KcSk",
        "colab_type": "code",
        "outputId": "4e747290-e344-4db0-a3da-ddd5f84d897a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob.clear_objects()\n",
        "alice.clear_objects()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:alice #objects:0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acAuyL1oKfOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 64\n",
        "        self.test_batch_size = 1000\n",
        "        self.epochs = 1\n",
        "        self.lr = 0.01\n",
        "        self.momentum = 0.5\n",
        "        self.no_cuda = False\n",
        "        self.seed = 1\n",
        "        self.log_interval = 10\n",
        "        self.save_model = False\n",
        "\n",
        "args = Arguments()\n",
        "\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u72Ko-MKiWT",
        "colab_type": "code",
        "outputId": "f99bab29-5110-47f0-ac99-49f7846b5cbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
        "    datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ]))\n",
        "    .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
        "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=args.test_batch_size, shuffle=True, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "26427392it [00:02, 10579162.24it/s]                             \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 71502.16it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4423680it [00:01, 3063989.61it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 26688.69it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOSJDXloKrVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6iMqJOIKxBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(args, model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
        "        model.send(data.location) # <-- NEW: send the model to the right location\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        model.get() # <-- NEW: get the model back\n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            loss = loss.get() # <-- NEW: get the loss back\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * args.batch_size, len(train_loader) * args.batch_size, #batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-7WcZAqKvxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(args, model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfnUqbs6K19Y",
        "colab_type": "code",
        "outputId": "90008ac0-a6b5-44ab-a0fc-5100696805f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Net().to(device)\n",
        "# TODO: Define your network architecture here\n",
        "\n",
        "#model = model.fix_precision().share(bob, alice, crypto_provider=crypto_provider,  requires_grad=True)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train(args, model, device, federated_train_loader, optimizer, epoch)\n",
        "    test(args, model, device, test_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60032 (0%)]\tLoss: 2.308013\n",
            "Train Epoch: 1 [640/60032 (1%)]\tLoss: 2.278277\n",
            "Train Epoch: 1 [1280/60032 (2%)]\tLoss: 2.223066\n",
            "Train Epoch: 1 [1920/60032 (3%)]\tLoss: 2.178230\n",
            "Train Epoch: 1 [2560/60032 (4%)]\tLoss: 2.119330\n",
            "Train Epoch: 1 [3200/60032 (5%)]\tLoss: 1.991134\n",
            "Train Epoch: 1 [3840/60032 (6%)]\tLoss: 1.848124\n",
            "Train Epoch: 1 [4480/60032 (7%)]\tLoss: 1.717725\n",
            "Train Epoch: 1 [5120/60032 (9%)]\tLoss: 1.529551\n",
            "Train Epoch: 1 [5760/60032 (10%)]\tLoss: 1.483605\n",
            "Train Epoch: 1 [6400/60032 (11%)]\tLoss: 1.268205\n",
            "Train Epoch: 1 [7040/60032 (12%)]\tLoss: 1.405404\n",
            "Train Epoch: 1 [7680/60032 (13%)]\tLoss: 1.000153\n",
            "Train Epoch: 1 [8320/60032 (14%)]\tLoss: 1.187712\n",
            "Train Epoch: 1 [8960/60032 (15%)]\tLoss: 1.226823\n",
            "Train Epoch: 1 [9600/60032 (16%)]\tLoss: 1.057866\n",
            "Train Epoch: 1 [10240/60032 (17%)]\tLoss: 0.980531\n",
            "Train Epoch: 1 [10880/60032 (18%)]\tLoss: 0.790167\n",
            "Train Epoch: 1 [11520/60032 (19%)]\tLoss: 0.850935\n",
            "Train Epoch: 1 [12160/60032 (20%)]\tLoss: 0.887532\n",
            "Train Epoch: 1 [12800/60032 (21%)]\tLoss: 1.071004\n",
            "Train Epoch: 1 [13440/60032 (22%)]\tLoss: 0.997539\n",
            "Train Epoch: 1 [14080/60032 (23%)]\tLoss: 1.040598\n",
            "Train Epoch: 1 [14720/60032 (25%)]\tLoss: 0.998435\n",
            "Train Epoch: 1 [15360/60032 (26%)]\tLoss: 0.936804\n",
            "Train Epoch: 1 [16000/60032 (27%)]\tLoss: 1.089932\n",
            "Train Epoch: 1 [16640/60032 (28%)]\tLoss: 0.964895\n",
            "Train Epoch: 1 [17280/60032 (29%)]\tLoss: 0.849959\n",
            "Train Epoch: 1 [17920/60032 (30%)]\tLoss: 0.938392\n",
            "Train Epoch: 1 [18560/60032 (31%)]\tLoss: 0.852902\n",
            "Train Epoch: 1 [19200/60032 (32%)]\tLoss: 0.695547\n",
            "Train Epoch: 1 [19840/60032 (33%)]\tLoss: 0.782272\n",
            "Train Epoch: 1 [20480/60032 (34%)]\tLoss: 0.646138\n",
            "Train Epoch: 1 [21120/60032 (35%)]\tLoss: 0.764626\n",
            "Train Epoch: 1 [21760/60032 (36%)]\tLoss: 0.880032\n",
            "Train Epoch: 1 [22400/60032 (37%)]\tLoss: 0.819817\n",
            "Train Epoch: 1 [23040/60032 (38%)]\tLoss: 0.718860\n",
            "Train Epoch: 1 [23680/60032 (39%)]\tLoss: 0.879666\n",
            "Train Epoch: 1 [24320/60032 (41%)]\tLoss: 0.653108\n",
            "Train Epoch: 1 [24960/60032 (42%)]\tLoss: 0.667524\n",
            "Train Epoch: 1 [25600/60032 (43%)]\tLoss: 0.810236\n",
            "Train Epoch: 1 [26240/60032 (44%)]\tLoss: 0.764628\n",
            "Train Epoch: 1 [26880/60032 (45%)]\tLoss: 0.829024\n",
            "Train Epoch: 1 [27520/60032 (46%)]\tLoss: 0.790037\n",
            "Train Epoch: 1 [28160/60032 (47%)]\tLoss: 0.708481\n",
            "Train Epoch: 1 [28800/60032 (48%)]\tLoss: 0.810579\n",
            "Train Epoch: 1 [29440/60032 (49%)]\tLoss: 0.773166\n",
            "Train Epoch: 1 [30080/60032 (50%)]\tLoss: 0.827062\n",
            "Train Epoch: 1 [30720/60032 (51%)]\tLoss: 0.567246\n",
            "Train Epoch: 1 [31360/60032 (52%)]\tLoss: 0.664463\n",
            "Train Epoch: 1 [32000/60032 (53%)]\tLoss: 0.760406\n",
            "Train Epoch: 1 [32640/60032 (54%)]\tLoss: 0.641489\n",
            "Train Epoch: 1 [33280/60032 (55%)]\tLoss: 0.741137\n",
            "Train Epoch: 1 [33920/60032 (57%)]\tLoss: 0.657262\n",
            "Train Epoch: 1 [34560/60032 (58%)]\tLoss: 0.835514\n",
            "Train Epoch: 1 [35200/60032 (59%)]\tLoss: 0.478473\n",
            "Train Epoch: 1 [35840/60032 (60%)]\tLoss: 0.633705\n",
            "Train Epoch: 1 [36480/60032 (61%)]\tLoss: 0.672175\n",
            "Train Epoch: 1 [37120/60032 (62%)]\tLoss: 0.546396\n",
            "Train Epoch: 1 [37760/60032 (63%)]\tLoss: 0.937996\n",
            "Train Epoch: 1 [38400/60032 (64%)]\tLoss: 0.777359\n",
            "Train Epoch: 1 [39040/60032 (65%)]\tLoss: 0.670780\n",
            "Train Epoch: 1 [39680/60032 (66%)]\tLoss: 0.620410\n",
            "Train Epoch: 1 [40320/60032 (67%)]\tLoss: 0.669821\n",
            "Train Epoch: 1 [40960/60032 (68%)]\tLoss: 0.650091\n",
            "Train Epoch: 1 [41600/60032 (69%)]\tLoss: 0.654478\n",
            "Train Epoch: 1 [42240/60032 (70%)]\tLoss: 0.632022\n",
            "Train Epoch: 1 [42880/60032 (71%)]\tLoss: 0.910738\n",
            "Train Epoch: 1 [43520/60032 (72%)]\tLoss: 0.729278\n",
            "Train Epoch: 1 [44160/60032 (74%)]\tLoss: 0.550934\n",
            "Train Epoch: 1 [44800/60032 (75%)]\tLoss: 0.766787\n",
            "Train Epoch: 1 [45440/60032 (76%)]\tLoss: 0.729633\n",
            "Train Epoch: 1 [46080/60032 (77%)]\tLoss: 0.729162\n",
            "Train Epoch: 1 [46720/60032 (78%)]\tLoss: 0.847959\n",
            "Train Epoch: 1 [47360/60032 (79%)]\tLoss: 0.693793\n",
            "Train Epoch: 1 [48000/60032 (80%)]\tLoss: 0.471232\n",
            "Train Epoch: 1 [48640/60032 (81%)]\tLoss: 0.515306\n",
            "Train Epoch: 1 [49280/60032 (82%)]\tLoss: 0.785134\n",
            "Train Epoch: 1 [49920/60032 (83%)]\tLoss: 0.615005\n",
            "Train Epoch: 1 [50560/60032 (84%)]\tLoss: 0.768344\n",
            "Train Epoch: 1 [51200/60032 (85%)]\tLoss: 0.526255\n",
            "Train Epoch: 1 [51840/60032 (86%)]\tLoss: 0.682048\n",
            "Train Epoch: 1 [52480/60032 (87%)]\tLoss: 0.657710\n",
            "Train Epoch: 1 [53120/60032 (88%)]\tLoss: 0.611099\n",
            "Train Epoch: 1 [53760/60032 (90%)]\tLoss: 0.812021\n",
            "Train Epoch: 1 [54400/60032 (91%)]\tLoss: 0.660186\n",
            "Train Epoch: 1 [55040/60032 (92%)]\tLoss: 0.783419\n",
            "Train Epoch: 1 [55680/60032 (93%)]\tLoss: 0.751886\n",
            "Train Epoch: 1 [56320/60032 (94%)]\tLoss: 0.579836\n",
            "Train Epoch: 1 [56960/60032 (95%)]\tLoss: 0.480562\n",
            "Train Epoch: 1 [57600/60032 (96%)]\tLoss: 0.764124\n",
            "Train Epoch: 1 [58240/60032 (97%)]\tLoss: 0.518888\n",
            "Train Epoch: 1 [58880/60032 (98%)]\tLoss: 0.547281\n",
            "Train Epoch: 1 [59520/60032 (99%)]\tLoss: 0.625971\n",
            "\n",
            "Test set: Average loss: 0.6434, Accuracy: 7467/10000 (75%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7dB8gxeK6cj",
        "colab_type": "code",
        "outputId": "530fc78d-a250-43f7-8e36-dcee9ab2de64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "from torch import optim\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in federated_train_loader:\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images = images.view(images.shape[0], -1)\n",
        "        optimizer.zero_grad()\n",
        "        # TODO: Training pass\n",
        "        model.send(images.location)\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        model.get()\n",
        "        \n",
        "        running_loss += loss.get().item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(federated_train_loader)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/syft/workers/base.py:385: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  response = command(*args, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss: 1.3803808731056735\n",
            "Training loss: 0.7535660138516538\n",
            "Training loss: 0.6100125259427882\n",
            "Training loss: 0.5415643302680079\n",
            "Training loss: 0.505528702474098\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD9a5hFYLJfH",
        "colab_type": "code",
        "outputId": "bee44e6a-8714-4f31-aee1-92b9010860ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import helper\n",
        "import helper\n",
        "\n",
        "def view_classify(img, ps, version=\"MNIST\"):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    if version == \"MNIST\":\n",
        "        ax2.set_yticklabels(np.arange(10))\n",
        "    elif version == \"Fashion\":\n",
        "        ax2.set_yticklabels(['T-shirt/top',\n",
        "                            'Trouser',\n",
        "                            'Pullover',\n",
        "                            'Dress',\n",
        "                            'Coat',\n",
        "                            'Sandal',\n",
        "                            'Shirt',\n",
        "                            'Sneaker',\n",
        "                            'Bag',\n",
        "                            'Ankle Boot'], size='small');\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "\n",
        "# Test out your network!\n",
        "\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = dataiter.next()\n",
        "img = images[0]\n",
        "# Convert 2D image to 1D vector\n",
        "img = img.resize_(1, 784)\n",
        "\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logps = model(img)\n",
        "\n",
        "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "ps = torch.exp(logps)\n",
        "\n",
        "# Plot the image and probabilities\n",
        "view_classify(img.resize_(1, 28, 28), ps, version='Fashion')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAAGKCAYAAACrcD/sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 370,
              "height": 197
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNfscJLFLLDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}