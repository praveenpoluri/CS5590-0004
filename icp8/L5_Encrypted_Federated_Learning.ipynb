{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "L5 - Encrypted Federated Learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveenpoluri/CS5590-0004/blob/master/icp8/L5_Encrypted_Federated_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-9zRNvlyg8d",
        "colab_type": "text"
      },
      "source": [
        "# Section: Securing Federated Learning\n",
        "\n",
        "- Lesson 1: Trusted Aggregator\n",
        "- Lesson 2: Intro to Additive Secret Sharing\n",
        "- Lesson 3: Intro to Fixed Precision Encoding\n",
        "- Lesson 4: Secret Sharing + Fixed Precision in PySyft\n",
        "- Final Project: Federated Learning wtih Encrypted Gradient Aggregation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpoP5r4pyg8e",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Federated Learning with a Trusted Aggregator\n",
        "\n",
        "In the last section, we learned how to train a model on a distributed dataset using Federated Learning. In particular, the last project aggregated gradients directly from one data owner to another. \n",
        "\n",
        "However, while in some cases it could be ideal to do this, what would be even better is to be able to choose a neutral third party to perform the aggregation.\n",
        "\n",
        "As it turns out, we can use the same tools we used previously to accomplish this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_p_SUmJyg8f",
        "colab_type": "text"
      },
      "source": [
        "# Project: Federated Learning with a Trusted Aggregator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co2Ce0CNyg8g",
        "colab_type": "text"
      },
      "source": [
        "### Step 1: Create Data Owners"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH_EmY1EysB1",
        "colab_type": "code",
        "outputId": "5c905a7a-33f0-462c-c606-d799d308fb33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        }
      },
      "source": [
        "!pip install syft"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: syft in /usr/local/lib/python3.6/dist-packages (0.1.21a1)\n",
            "Requirement already satisfied: websocket-client>=0.56.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.56.0)\n",
            "Requirement already satisfied: msgpack>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from syft) (0.6.1)\n",
            "Requirement already satisfied: tf-encrypted>=0.5.4 in /usr/local/lib/python3.6/dist-packages (from syft) (0.5.6)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.3.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.16.4)\n",
            "Requirement already satisfied: lz4>=2.1.6 in /usr/local/lib/python3.6/dist-packages (from syft) (2.1.10)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.21.2)\n",
            "Requirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.1)\n",
            "Requirement already satisfied: zstd>=1.4.0.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0.0)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.0)\n",
            "Requirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Requirement already satisfied: websockets>=7.0 in /usr/local/lib/python3.6/dist-packages (from syft) (8.0)\n",
            "Requirement already satisfied: flask-socketio>=3.3.2 in /usr/local/lib/python3.6/dist-packages (from syft) (4.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client>=0.56.0->syft) (1.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (5.1.1)\n",
            "Requirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (4.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (0.13.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (1.3.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (0.15.4)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (2.10.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (7.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (1.1.0)\n",
            "Requirement already satisfied: python-socketio>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from flask-socketio>=3.3.2->syft) (4.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.33.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.7.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.11.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.1.7)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.8.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->syft) (0.46)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=1.0.2->syft) (1.1.1)\n",
            "Requirement already satisfied: python-engineio>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from python-socketio>=2.1.0->flask-socketio>=3.3.2->syft) (3.8.2.post1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKg8RQSqyg8g",
        "colab_type": "code",
        "outputId": "d8e59446-c6ac-43a0-e245-b90d2f26722e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import syft as sy\n",
        "import torch as th\n",
        "from torch import nn, optim\n",
        "\n",
        "hook = sy.TorchHook(th)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0714 16:23:50.295611 140425218107264 hook.py:98] Torch was already hooked... skipping hooking process\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brR-QwtByovp",
        "colab_type": "code",
        "outputId": "1dd2bad5-45b2-46f2-a71e-c14c89b76d6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "# create a couple workers\n",
        "\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
        "secure_worker = sy.VirtualWorker(hook, id=\"secure_worker\")\n",
        "\n",
        "# this step is important in the real-world application.\n",
        "# You need to inform the workers of others existance\n",
        "# you will probably have an ssh or http worker, not a virtual worker.\n",
        "\n",
        "bob.add_workers([alice, secure_worker])\n",
        "alice.add_workers([bob, secure_worker])\n",
        "secure_worker.add_workers([alice, bob])"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0714 16:23:54.134626 140425218107264 base.py:628] Worker alice already exists. Replacing old worker which could cause                     unexpected behavior\n",
            "W0714 16:23:54.142057 140425218107264 base.py:628] Worker secure_worker already exists. Replacing old worker which could cause                     unexpected behavior\n",
            "W0714 16:23:54.145772 140425218107264 base.py:628] Worker bob already exists. Replacing old worker which could cause                     unexpected behavior\n",
            "W0714 16:23:54.149968 140425218107264 base.py:628] Worker secure_worker already exists. Replacing old worker which could cause                     unexpected behavior\n",
            "W0714 16:23:54.155031 140425218107264 base.py:628] Worker alice already exists. Replacing old worker which could cause                     unexpected behavior\n",
            "W0714 16:23:54.158508 140425218107264 base.py:628] Worker bob already exists. Replacing old worker which could cause                     unexpected behavior\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:secure_worker #objects:45>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ-yj1iEy-0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A Toy Dataset\n",
        "data = th.tensor([[0,0],[0,1],[1,0],[1,1.]], requires_grad=True)\n",
        "target = th.tensor([[0],[0],[1],[1.]], requires_grad=True)\n",
        "\n",
        "# get pointers to training data on each worker by\n",
        "# sending some training data to bob and alice\n",
        "bobs_data = data[0:2].send(bob)\n",
        "bobs_target = target[0:2].send(bob)\n",
        "\n",
        "alices_data = data[2:].send(alice)\n",
        "alices_target = target[2:].send(alice)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPinzIzsyg8l",
        "colab_type": "text"
      },
      "source": [
        "### Step 2: Create the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuQKR-Ckyg8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Iniitalize A Toy Model\n",
        "model = nn.Linear(2,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1Jy5Iukyg8o",
        "colab_type": "text"
      },
      "source": [
        "### Step 3: Send a Copy of The Model to Alice and Bob"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bG1JWYzyg8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bobs_model = model.copy().send(bob) \n",
        "alices_model = model.copy().send(alice) \n",
        "\n",
        "bobs_opt = optim.SGD(params=bobs_model.parameters(), lr=0.1)\n",
        "alices_opt = optim.SGD(params=alices_model.parameters(), lr=0.1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdjyo1Gkyg8q",
        "colab_type": "text"
      },
      "source": [
        "### Step 4: Train Bob's and Alice's Models (in parallel)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmtzmlcDyg8r",
        "colab_type": "code",
        "outputId": "35a3118c-3aee-4119-8fd0-08254168139f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "    # Train Bob's Model\n",
        "    bobs_opt.zero_grad()\n",
        "    bobs_pred = bobs_model(bobs_data)\n",
        "    bobs_loss = ((bobs_pred - bobs_target)**2).mean()\n",
        "    bobs_loss.backward()\n",
        "\n",
        "    bobs_opt.step()\n",
        "    bobs_loss = bobs_loss.get().data\n",
        "    print(f'Bob loss {bobs_loss}')\n",
        "\n",
        "    # Train Alice's Model\n",
        "    alices_opt.zero_grad()\n",
        "    alices_pred = alices_model(alices_data)\n",
        "    alices_loss = ((alices_pred - alices_target)**2).mean()\n",
        "    alices_loss.backward()\n",
        "\n",
        "    alices_opt.step()\n",
        "    alices_loss = alices_loss.get().data\n",
        "    print(f'alice loss {alices_loss}')\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bob loss 0.05534515529870987\n",
            "alice loss 0.01747691072523594\n",
            "Bob loss 0.051183927804231644\n",
            "alice loss 0.015975693240761757\n",
            "Bob loss 0.04734087735414505\n",
            "alice loss 0.014604834839701653\n",
            "Bob loss 0.043789271265268326\n",
            "alice loss 0.013352017849683762\n",
            "Bob loss 0.04050569236278534\n",
            "alice loss 0.012206793762743473\n",
            "Bob loss 0.03746919706463814\n",
            "alice loss 0.011159845627844334\n",
            "Bob loss 0.03466079756617546\n",
            "alice loss 0.010202687233686447\n",
            "Bob loss 0.03206315264105797\n",
            "alice loss 0.009327633306384087\n",
            "Bob loss 0.02966032549738884\n",
            "alice loss 0.008527625352144241\n",
            "Bob loss 0.027437642216682434\n",
            "alice loss 0.007796232122927904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HT6cy1gMyg8s",
        "colab_type": "text"
      },
      "source": [
        "### Step 5: Send Both Updated Models to a Secure Worker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S2qpEoZyg8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alices_model.move(secure_worker) # the move function iterates on all objects in alice and call send on it. NOTEICE: inline function\n",
        "bobs_model.move(secure_worker)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEZZbRDx28Kw",
        "colab_type": "code",
        "outputId": "268cba13-287e-4ab0-aef6-d5c65114b1f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "secure_worker._objects # can you identify those objects in the Secure worker?"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1582595598: Parameter containing:\n",
              " tensor([[0.6751, 0.0129]], requires_grad=True),\n",
              " 2008197476: Parameter containing:\n",
              " tensor([[ 0.5692, -0.0800]], requires_grad=True),\n",
              " 2608838588: Parameter containing:\n",
              " tensor([[0.2492, 0.0526]], requires_grad=True),\n",
              " 4337864218: Parameter containing:\n",
              " tensor([0.0418], requires_grad=True),\n",
              " 6487486470: Parameter containing:\n",
              " tensor([0.1919], requires_grad=True),\n",
              " 7429185308: Parameter containing:\n",
              " tensor([[ 0.1746, -0.1485]], requires_grad=True),\n",
              " 8166943004: Parameter containing:\n",
              " tensor([0.1012], requires_grad=True),\n",
              " 8799551038: Parameter containing:\n",
              " tensor([0.6128], requires_grad=True),\n",
              " 10000900803: Parameter containing:\n",
              " tensor([0.0791], requires_grad=True),\n",
              " 10847129305: Parameter containing:\n",
              " tensor([[0.3692, 0.0321]], requires_grad=True),\n",
              " 14717270572: Parameter containing:\n",
              " tensor([[0.5185, 0.0208]], requires_grad=True),\n",
              " 19401305109: Parameter containing:\n",
              " tensor([0.0615], requires_grad=True),\n",
              " 20609823856: Parameter containing:\n",
              " tensor([0.7213], requires_grad=True),\n",
              " 22252685453: Parameter containing:\n",
              " tensor([[0.4504, 0.0251]], requires_grad=True),\n",
              " 23082653323: Parameter containing:\n",
              " tensor([[-0.0177, -0.3100]], requires_grad=True),\n",
              " 24279169644: Parameter containing:\n",
              " tensor([0.1258], requires_grad=True),\n",
              " 25236913227: Parameter containing:\n",
              " tensor([[ 0.6686, -0.0619]], requires_grad=True),\n",
              " 29450968774: Parameter containing:\n",
              " tensor([0.4124], requires_grad=True),\n",
              " 30465720608: Parameter containing:\n",
              " tensor([0.3176], requires_grad=True),\n",
              " 34518745918: Parameter containing:\n",
              " tensor([0.0476], requires_grad=True),\n",
              " 34875498207: Parameter containing:\n",
              " tensor([[0.6296, 0.0150]], requires_grad=True),\n",
              " 36378005306: Parameter containing:\n",
              " tensor([[ 0.1000, -0.1636]], requires_grad=True),\n",
              " 36592206323: Parameter containing:\n",
              " tensor([0.4698], requires_grad=True),\n",
              " 36995532906: Parameter containing:\n",
              " tensor([0.0895], requires_grad=True),\n",
              " 39066871108: Parameter containing:\n",
              " tensor([0.0698], requires_grad=True),\n",
              " 44611787052: Parameter containing:\n",
              " tensor([0.1152], requires_grad=True),\n",
              " 45497926723: Parameter containing:\n",
              " tensor([[0.7807, 0.0083]], requires_grad=True),\n",
              " 47168952924: Parameter containing:\n",
              " tensor([0.0367], requires_grad=True),\n",
              " 48083634868: Parameter containing:\n",
              " tensor([0.3619], requires_grad=True),\n",
              " 49555072677: Parameter containing:\n",
              " tensor([[ 0.4398, -0.1032]], requires_grad=True),\n",
              " 51085720417: Parameter containing:\n",
              " tensor([[0.5777, 0.0176]], requires_grad=True),\n",
              " 54441333980: Parameter containing:\n",
              " tensor([[ 0.1000, -0.1589]], requires_grad=True),\n",
              " 57996246319: Parameter containing:\n",
              " tensor([[0.7150, 0.0111]], requires_grad=True),\n",
              " 61770311528: Parameter containing:\n",
              " tensor([[0.2487, 0.0530]], requires_grad=True),\n",
              " 65810626326: Parameter containing:\n",
              " tensor([0.2146], requires_grad=True),\n",
              " 67329482514: Parameter containing:\n",
              " tensor([0.2446], requires_grad=True),\n",
              " 70303101378: Parameter containing:\n",
              " tensor([0.5355], requires_grad=True),\n",
              " 72197064596: Parameter containing:\n",
              " tensor([[ 0.7093, -0.0543]], requires_grad=True),\n",
              " 78924038029: Parameter containing:\n",
              " tensor([[0.7500, 0.0096]], requires_grad=True),\n",
              " 80847824916: Parameter containing:\n",
              " tensor([[ 0.2719, -0.1321]], requires_grad=True),\n",
              " 81477348969: Parameter containing:\n",
              " tensor([[ 0.3611, -0.1169]], requires_grad=True),\n",
              " 82825027254: Parameter containing:\n",
              " tensor([0.0541], requires_grad=True),\n",
              " 87509410399: Parameter containing:\n",
              " tensor([[ 0.2824, -0.1676]], requires_grad=True),\n",
              " 89638017276: Parameter containing:\n",
              " tensor([[ 0.6222, -0.0704]], requires_grad=True),\n",
              " 91852013902: tensor([ -118677462231998590, -1004707423846455877,  -201635755920084806,\n",
              "         -4363826903137083331, -1461024569070867654]),\n",
              " 93066289881: Parameter containing:\n",
              " tensor([0.7208], requires_grad=True),\n",
              " 93731502190: Parameter containing:\n",
              " tensor([[ 0.5088, -0.0909]], requires_grad=True),\n",
              " 94766747587: Parameter containing:\n",
              " tensor([0.8117], requires_grad=True),\n",
              " 99826365891: Parameter containing:\n",
              " tensor([0.2787], requires_grad=True)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO9s8TmOyg8v",
        "colab_type": "text"
      },
      "source": [
        "### Step 6: Average The Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RPMqJTB3wlE",
        "colab_type": "code",
        "outputId": "d79e775a-8b70-48ef-96ff-9cea147dafd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# A pytorch trick: to set the weights: you have to either access the data[idx] \n",
        "# or wrap the set function with (with torch.no_grad():)\n",
        "# below we illustrate the first way\n",
        "# the next cell demonstrates the complete way:\n",
        "\n",
        "model.weight.data[0].set_(((alices_model.weight.data + bobs_model.weight.data) / 2).get())\n",
        "model.bias.data[0].set_(((alices_model.bias.data + bobs_model.bias.data) / 2).get())"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5018])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCLNoxd3yg8y",
        "colab_type": "text"
      },
      "source": [
        "### Step 7: The complete solution over multiple training sessions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUV-_tW2yg80",
        "colab_type": "code",
        "outputId": "81713186-9d53-4649-f399-863125836772",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "iterations = 10\n",
        "worker_iters = 5\n",
        "\n",
        "for a_iter in range(iterations):\n",
        "\n",
        "    bobs_model = model.copy().send(bob)\n",
        "    alices_model = model.copy().send(alice)\n",
        "\n",
        "    bobs_opt = optim.SGD(params=bobs_model.parameters(), lr=0.1)\n",
        "    alices_opt = optim.SGD(params=alices_model.parameters(), lr=0.1)\n",
        "\n",
        "    for wi in range(worker_iters):\n",
        "        # Train Bob's Model\n",
        "        bobs_opt.zero_grad()\n",
        "        bobs_pred = bobs_model(bobs_data)\n",
        "        bobs_loss = ((bobs_pred - bobs_target) ** 2).sum()\n",
        "        bobs_loss.backward()\n",
        "\n",
        "        bobs_opt.step()\n",
        "        bobs_loss = bobs_loss.get().data\n",
        "\n",
        "        # Train Alice's Model\n",
        "        alices_opt.zero_grad()\n",
        "        alices_pred = alices_model(alices_data)\n",
        "        alices_loss = ((alices_pred - alices_target) ** 2).sum()\n",
        "        alices_loss.backward()\n",
        "\n",
        "        alices_opt.step()\n",
        "        alices_loss = alices_loss.get().data\n",
        "\n",
        "    alices_model.move(secure_worker)\n",
        "    bobs_model.move(secure_worker)\n",
        "\n",
        "    with th.no_grad():\n",
        "\n",
        "        model.weight.set_(((alices_model.weight.data + bobs_model.weight.data) / 2).get())\n",
        "        model.bias.set_(((alices_model.bias.data + bobs_model.bias.data) / 2).get())\n",
        "    \n",
        "    print(\"Bob:\" + str(bobs_loss) + \" Alice:\" + str(alices_loss))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bob:tensor(0.1277) Alice:tensor(0.0411)\n",
            "Bob:tensor(0.0728) Alice:tensor(0.0136)\n",
            "Bob:tensor(0.0436) Alice:tensor(0.0050)\n",
            "Bob:tensor(0.0272) Alice:tensor(0.0018)\n",
            "Bob:tensor(0.0176) Alice:tensor(0.0006)\n",
            "Bob:tensor(0.0118) Alice:tensor(0.0002)\n",
            "Bob:tensor(0.0081) Alice:tensor(3.5445e-05)\n",
            "Bob:tensor(0.0057) Alice:tensor(2.5743e-06)\n",
            "Bob:tensor(0.0041) Alice:tensor(9.4453e-07)\n",
            "Bob:tensor(0.0030) Alice:tensor(5.8414e-06)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11abe6ojyg84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = model(data)\n",
        "loss = ((preds - target) ** 2).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0hsXnTNyg87",
        "colab_type": "code",
        "outputId": "22d30d97-6efa-4e67-9b2c-33e2b411f284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "print(preds)\n",
        "print(target)\n",
        "print(loss.data)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.1256],\n",
            "        [0.1026],\n",
            "        [0.8707],\n",
            "        [0.8477]], grad_fn=<AddmmBackward>)\n",
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.]], requires_grad=True)\n",
            "AutogradTensor>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
            "\t-> (Wrapper)>[PointerTensor | me:83834359868 -> bob:48492103601]\n",
            "\t-> (Wrapper)>[PointerTensor | me:47721487910 -> alice:32984600832]\n",
            "\t-> (Wrapper)>[PointerTensor | me:5922426518 -> ted:43222873002]\n",
            "\t-> (Wrapper)>[PointerTensor | me:99005764682 -> carol:83366780188]\n",
            "\t*crypto provider: crypto_provider*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76nNRwAIyg89",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Intro to Additive Secret Sharing\n",
        "\n",
        "While being able to have a trusted third party to perform the aggregation is certainly nice, in an ideal setting we wouldn't have to trust anyone at all. This is where Cryptography can provide an interesting alterantive. \n",
        "\n",
        "Specifically, we're going to be looking at a simple protocol for Secure Multi-Party Computation called Additive Secret Sharing. This protocol will allow multiple parties (of size 3 or more) to aggregate their gradients without the use of a trusted 3rd party to perform the aggregation. In other words, we can add 3 numbers together from 3 different people without anyone ever learning the inputs of any other actors.\n",
        "\n",
        "Let's start by considering the number 5, which we'll put into a varible x"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgBkWPGQyg89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmmK50kzyg8_",
        "colab_type": "text"
      },
      "source": [
        "Let's say we wanted to SHARE the ownership of this number between two people, Alice and Bob. We could split this number into two shares, 2, and 3, and give one to Alice and one to Bob"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8g8BuYuyg8_",
        "colab_type": "code",
        "outputId": "04559cca-cff0-4f4b-dcd5-408e7314a30c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob_x_share = 2\n",
        "alice_x_share = 3\n",
        "\n",
        "decrypted_x = bob_x_share + alice_x_share\n",
        "decrypted_x"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQgRH61vyg9C",
        "colab_type": "text"
      },
      "source": [
        "Note that neither Bob nor Alice know the value of x. They only know the value of their own SHARE of x. Thus, the true value of X is hidden (i.e., encrypted). \n",
        "\n",
        "The truly amazing thing, however, is that Alice and Bob can still compute using this value! They can perform arithmetic over the hidden value! Let's say Bob and Alice wanted to multiply this value by 2! If each of them multiplied their respective share by 2, then the hidden number between them is also multiplied! Check it out!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8dFgnKqyg9C",
        "colab_type": "code",
        "outputId": "c352424a-e219-4522-f109-85851f5c3088",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob_x_share *= 2\n",
        "alice_x_share *= 2\n",
        "\n",
        "decrypted_x = bob_x_share + alice_x_share\n",
        "decrypted_x"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3yKEyfuyg9M",
        "colab_type": "text"
      },
      "source": [
        "This even works for addition between two shared values!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNeUyPpmyg9N",
        "colab_type": "code",
        "outputId": "29a6e6e9-8964-4a07-dcfa-24dd58e48d26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# encrypted \"5\"\n",
        "bob_x_share = 2\n",
        "alice_x_share = 3\n",
        "\n",
        "# encrypted \"7\"\n",
        "bob_y_share = 5\n",
        "alice_y_share = 2\n",
        "\n",
        "# encrypted 5 + 7\n",
        "bob_z_share = bob_x_share + bob_y_share\n",
        "alice_z_share = alice_x_share + alice_y_share\n",
        "\n",
        "decrypted_z = bob_z_share + alice_z_share\n",
        "decrypted_z"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTYo-67Cyg9R",
        "colab_type": "text"
      },
      "source": [
        "As you can see, we just added two numbers together while they were still encrypted ( you are the dealer, thus still can see --and know everything-- but Alice and Bob did not really know anything about the overall deal --the sum of the numbers; the secrete--)\n",
        "\n",
        "In this case, however, to keep the secrete is not about the relaiability / integrity of the person who holds it, rather the fact that those shareholders do not know each other!!!\n",
        "\n",
        "One small tweak - notice that since all our numbers are positive, it's possible for each share to reveal a little bit of information about the hidden value, namely, it's always greater than the share. Thus, if Bob has a share \"3\" then he knows that the encrypted value is at least 3.\n",
        "\n",
        "This would be quite bad, but can be solved through a simple fix. Decryption happens by summing all the shares together MODULUS some constant."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-rBg_wXyg9S",
        "colab_type": "code",
        "outputId": "6670e6c0-2576-4609-d6ef-cf58c7773d51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "x = 5\n",
        "\n",
        "Q = 9923 # the little fix; a very large prime number\n",
        "\n",
        "bob_x_share = 1525 # give bob a random number.. try with negatives\n",
        "\n",
        "alice_x_share = Q - bob_x_share + x\n",
        "\n",
        "print(f'Bob share= {bob_x_share}')\n",
        "print(f'Alice share= {alice_x_share}')\n",
        "print(f'Add both shares= {bob_x_share + alice_x_share}... Wrong secrete')"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bob share= 1525\n",
            "Alice share= 8403\n",
            "Add both shares= 9928... Wrong secrete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWwHr0-Cyg9W",
        "colab_type": "code",
        "outputId": "136c884b-7f50-49d4-9ad4-8bf8ff5c1e2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Decryption happens by summing all the shares together MODULUS some constant\n",
        "\n",
        "(bob_x_share + alice_x_share) % Q"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HObwFt8yg9Z",
        "colab_type": "text"
      },
      "source": [
        "So now, as you can see, both shares are wildly larger than the number being shared, meaning that individual shares no longer leak this inforation. However, all the properties we discussed earlier still hold! (addition, encryption, decryption, etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIXwf6S4yg9a",
        "colab_type": "text"
      },
      "source": [
        "# Project: Build Methods for Encrypt, Decrypt, and Add \n",
        "\n",
        "In this project, you must take the lessons we learned in the last section and write general methods for encrypt, decrypt, and add. Store shares for a variable in a tuple like so:  `x_share = (2,5,7)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMz0yE45yg9c",
        "colab_type": "text"
      },
      "source": [
        "Even though normally those shares would be distributed among several workers, you can store them in ordered tuples like this for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aI3TJxw4yg9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "Q = 23740629843760239486723\n",
        "\n",
        "# accepts a secrete and shares it among n_share, returns a tuple with n_share shares\n",
        "def encrypt(x, n_share=3):\n",
        "    \n",
        "    shares = list()\n",
        "    \n",
        "    for i in range(n_share-1):\n",
        "        shares.append(random.randint(0,Q))\n",
        "        \n",
        "    shares.append(Q - (sum(shares) % Q) + x)\n",
        "    \n",
        "    return tuple(shares)\n",
        "\n",
        "  # accepts a tuple of shares and return the decrypted values\n",
        "def decrypt(shares):\n",
        "    return sum(shares) % Q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_43oLAEDyg9e",
        "colab_type": "code",
        "outputId": "8d65d77f-465c-4417-a35e-b11649658836",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "shares = encrypt(x=7, n_share=10)\n",
        "shares"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11846388035402961246969,\n",
              " 12974871210695313376904,\n",
              " 10155052958965412165918,\n",
              " 7926239489144134908440,\n",
              " 14962645694711250721143,\n",
              " 5524858162704518160081,\n",
              " 2025871261317281887348,\n",
              " 14510315535076991266375,\n",
              " 17340361715318757431266,\n",
              " 21436545155464576269178)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyNaADMKyg9g",
        "colab_type": "code",
        "outputId": "28a20e7d-fb73-4d88-c48b-1200f7ca0a2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decrypt(shares)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9tKua0Lyg9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add(a, b):\n",
        "    c = list()\n",
        "    assert(len(a) == len(b))\n",
        "    for i in range(len(a)):\n",
        "        c.append((a[i] + b[i]) % Q)\n",
        "    return tuple(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gupg7bAKyg9k",
        "colab_type": "code",
        "outputId": "0c947006-e377-467e-bf0f-b103a48fa925",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# run this block of code multiple times, what do you notice baout x and y?\n",
        "\n",
        "x = encrypt(5)\n",
        "print(x)\n",
        "y = encrypt(7)\n",
        "print(y)\n",
        "\n",
        "z = add(x,y)\n",
        "decrypt(z)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20838997114397793423993, 22650060201527303191086, 3992202371595382358372)\n",
            "(1226278995304026279156, 19493661577733317030758, 3020689270722896176816)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmRCxZ6Nyg9m",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Intro to Fixed Precision Encoding\n",
        "\n",
        "As you may remember, our goal is to aggregate gradients using this new Secret Sharing technique. However, the protocol we've just explored in the last section uses positive integers. However, our neural network weights are NOT integers. Instead, our weights are decimals (floating point numbers).\n",
        "\n",
        "Not a huge deal! We just need to use a fixed precision encoding, which lets us do computation over decimal numbers using integers!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSHHm-Oryg9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BASE= 10  # integer numbers (normal numbers)\n",
        "PRECISION= 3  # how many porecisions after the decimal point to encode\n",
        "Q = 23740629843760239486723 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL3R5pU0yg9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode(x):\n",
        "    return int((x * (BASE ** PRECISION)) % Q)\n",
        "\n",
        "def decode(x):\n",
        "    return (x if x <= Q/2 else x - Q) / BASE**PRECISION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwXUQeqpyg9r",
        "colab_type": "code",
        "outputId": "d5e6eaea-1df1-41cb-a519-33bb0bf431f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "encode(-0.600)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23740629843760239345664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty3s8XYGyg9v",
        "colab_type": "code",
        "outputId": "c3067c1c-980f-474c-e8a0-37334c09e2b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decode(9323)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.323"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdFGoHbsyg9y",
        "colab_type": "code",
        "outputId": "d79c1b2c-6681-4c3d-ec80-043f9ff62c8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# run this cell multiple times and notice the changes\n",
        "\n",
        "x = encrypt(encode(5.5))\n",
        "y = encrypt(encode(5.5))\n",
        "z = add(x,y)\n",
        "\n",
        "\n",
        "print(f'Value of x = {x}')\n",
        "print(f'Value of y = {y}')\n",
        "print(f'Value of sum = {z}')\n",
        "print(f'decoded sum = {decode(decrypt(z))}')"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Value of x = (6621519947868350902979, 8025422117786324907959, 9093687778105563681285)\n",
            "Value of y = (10686602354860089354438, 19719519396308305219380, 17075137936352084405128)\n",
            "Value of sum = (17308122302728440257417, 4004311670334390640616, 2428195870697408599690)\n",
            "decoded sum = 11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F5ef4l9yg91",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Secret Sharing + Fixed Precision in PySyft\n",
        "\n",
        "While writing things from scratch is certainly educational, PySyft makes a great deal of this much easier for us through its abstractions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lm9L0XPDyg91",
        "colab_type": "code",
        "outputId": "ea556719-e69d-4a1e-fd9c-fdaa65f2e122",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "# Its a good idea to restrat the environment at this point\n",
        "\n",
        "import syft as sy\n",
        "import torch as th\n",
        "from torch import nn, optim\n",
        "\n",
        "hook = sy.TorchHook(th)\n",
        "\n",
        "# create a couple workers\n",
        "\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
        "secure_worker = sy.VirtualWorker(hook, id=\"secure_worker\")\n",
        "\n",
        "\n",
        "bob.add_workers([alice, secure_worker])\n",
        "alice.add_workers([bob, secure_worker])\n",
        "secure_worker.add_workers([alice, bob])"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0714 16:26:49.426381 140425218107264 hook.py:98] Torch was already hooked... skipping hooking process\n",
            "W0714 16:26:49.429251 140425218107264 base.py:628] Worker alice already exists. Replacing old worker which could cause                     unexpected behavior\n",
            "W0714 16:26:49.430769 140425218107264 base.py:628] Worker secure_worker already exists. Replacing old worker which could cause                     unexpected behavior\n",
            "W0714 16:26:49.433279 140425218107264 base.py:628] Worker bob already exists. Replacing old worker which could cause                     unexpected behavior\n",
            "W0714 16:26:49.434546 140425218107264 base.py:628] Worker secure_worker already exists. Replacing old worker which could cause                     unexpected behavior\n",
            "W0714 16:26:49.437557 140425218107264 base.py:628] Worker alice already exists. Replacing old worker which could cause                     unexpected behavior\n",
            "W0714 16:26:49.439105 140425218107264 base.py:628] Worker bob already exists. Replacing old worker which could cause                     unexpected behavior\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:secure_worker #objects:89>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCmtFQT_yg94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = th.tensor([1,2,3,4,5]) ##### the following steps work for integer values only"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9MtKxllyg96",
        "colab_type": "text"
      },
      "source": [
        "### Secret Sharing Using PySyft\n",
        "\n",
        "We can share using the simple` .share()` method!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWPR4vZxyg97",
        "colab_type": "code",
        "outputId": "f45fcd31-032e-48fc-bbae-5176bc5373a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "x = x.share(bob, alice, secure_worker) # implemets additive secrete shares\n",
        "x # it's a pointer to three secrete shares"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[AdditiveSharingTensor]\n",
              "\t-> (Wrapper)>[PointerTensor | me:31707255745 -> bob:24270442513]\n",
              "\t-> (Wrapper)>[PointerTensor | me:69275446318 -> alice:95854070887]\n",
              "\t-> (Wrapper)>[PointerTensor | me:71560170694 -> secure_worker:62117102884]\n",
              "\t*crypto provider: me*"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JnJczV4yg99",
        "colab_type": "code",
        "outputId": "a05ed945-11c5-4233-f6a2-525b963e6ba4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "bob._objects # take a look at one of the shares.. Large random numbers --encrypted"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4164730689: tensor([[0., 0.],\n",
              "         [0., 1.]], requires_grad=True), 4556527595: tensor([[ 0.0511],\n",
              "         [-0.0198]], grad_fn=<AddmmBackward>), 20126619949: tensor([[1830708002507383895, 2263355130074537947]]), 21454551104: tensor([[4138977751660586335, 4129090394376407639],\n",
              "         [4130005867379347301, 4129428666750119995],\n",
              "         [4127893465457949495, 4125843393955993374],\n",
              "         [4139638634608415281, 4139151011653310749],\n",
              "         [4136304007953457938, 4127915038176218860],\n",
              "         [4125936806126740287, 4130400670610510207],\n",
              "         [4123456255369926993, 4132414902996903383],\n",
              "         [4138374107712638589, 4122947590620096571]]), 22229319681: tensor([[1167261756756035735],\n",
              "         [1167261756756035735],\n",
              "         [1167261756756035735],\n",
              "         [1167261756756035735],\n",
              "         [1167261756756035735],\n",
              "         [1167261756756035735],\n",
              "         [1167261756756035735],\n",
              "         [1167261756756035735]]), 24270442513: tensor([3018033052193549522, 4238951692305445015, 1378017496896172764,\n",
              "         3921585209512839588, 2721505074533999126]), 27063789006: tensor([-8000323665152941625]), 31797131174: tensor([[1075561881784774437],\n",
              "         [1084421667867912661],\n",
              "         [1084093641836640355],\n",
              "         [1071216563402263635],\n",
              "         [1075243568511233074],\n",
              "         [1079617576090895477],\n",
              "         [1079090002064313480],\n",
              "         [1080511751537061696]]), 33283181215: tensor([[-4968919904687818],\n",
              "         [ 8179295756518900],\n",
              "         [-3134104964202896],\n",
              "         [ 6226477353067388],\n",
              "         [ 8238888207129761],\n",
              "         [ 3959792395649463],\n",
              "         [ 8876724720437457],\n",
              "         [ 1307909944174353]]), 35324654758: tensor([[ 2406647636213275],\n",
              "         [-6453138446924949],\n",
              "         [-6125112415652643],\n",
              "         [ 6751966018724077],\n",
              "         [ 2724960909754638],\n",
              "         [-1649046669907765],\n",
              "         [-1121472643325768],\n",
              "         [-2543222116073984]]), 41250558902: tensor([[1830708002507383895],\n",
              "         [2263355130074537947]]), 41400850452: tensor([[  722019491897245640],\n",
              "         [ -852744589251803703],\n",
              "         [-3712053607542031584],\n",
              "         [-1567123816184368635],\n",
              "         [-3749442765269358833],\n",
              "         [  768037307751917480],\n",
              "         [-1633828678981129684],\n",
              "         [-2783480848929440830]]), 46567516546: tensor([[2377595232200136601, 2383638913840214287]]), 48492103601: tensor(28686063508086608), 53993437178: tensor([[-2406647636213275],\n",
              "         [ 6453138446924949],\n",
              "         [ 6125112415652643],\n",
              "         [-6751966018724077],\n",
              "         [-2724960909754638],\n",
              "         [ 1649046669907765],\n",
              "         [ 1121472643325768],\n",
              "         [ 2543222116073984]]), 58294597551: tensor([[1160108549806805032],\n",
              "         [1168968335889943256],\n",
              "         [1168640309858670950],\n",
              "         [1155763231424294230],\n",
              "         [1159790236533263669],\n",
              "         [1164164244112926072],\n",
              "         [1163636670086344075],\n",
              "         [1165058419559092291]]), 58423203506: tensor([[ 113527488561592630],\n",
              "         [1697546836913541723],\n",
              "         [4545151780632444293],\n",
              "         [2404962711847848493],\n",
              "         [4581364183604660591],\n",
              "         [  65037905360888026],\n",
              "         [2473483516660289939],\n",
              "         [3620802323967112899]]), 60174782169: tensor([[2496746663609287623],\n",
              "         [2487886877526149399],\n",
              "         [2488214903557421705],\n",
              "         [2501091981991798425],\n",
              "         [2497064976882828986],\n",
              "         [2492690969303166583],\n",
              "         [2493218543329748580],\n",
              "         [2491796793857000364]]), 66592158855: tensor([[ 7695031216954171],\n",
              "         [ -814370862423898],\n",
              "         [ 6493692087820905],\n",
              "         [ 3918782894947249],\n",
              "         [-7091114538005499],\n",
              "         [ 7588939351672908],\n",
              "         [ 1153940259685578],\n",
              "         [ 2925409132241462]]), 67349719825: tensor([[0.],\n",
              "         [0.]], requires_grad=True), 71302348306: tensor([2767404076142673010]), 72282334347: tensor([-7590213085410133677]), 74625618992: tensor([[3026230820672660937, 1013596260204113621],\n",
              "         [ 643283243862676468, 2046198317112848842],\n",
              "         [ 685795807377056590, 4100106974728583742],\n",
              "         [  76201530225555387,   52693750533038325],\n",
              "         [3852938711342070660, 3883829329333090197],\n",
              "         [1992683357071249859, 4394748627340567500],\n",
              "         [ 879880565724304350, 2724541129489391678],\n",
              "         [4367236917765869979, 3401196937300952730]]), 79062614970: tensor([[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         [0],\n",
              "         [0],\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]]), 88064707184: tensor([[ 1444038983794491280],\n",
              "         [-1705489178503607406],\n",
              "         [-7424107215084063168],\n",
              "         [-3134247632368737270],\n",
              "         [-7498885530538717666],\n",
              "         [ 1536074615503834960],\n",
              "         [-3267657357962259368],\n",
              "         [-5566961697858881660]]), 88379987850: tensor([[-2981203019061822],\n",
              "         [ 6274064183837928],\n",
              "         [-5430010387487383],\n",
              "         [ -689287814420234],\n",
              "         [-6606765142598334],\n",
              "         [-5452970365094586],\n",
              "         [ 1126654201260163],\n",
              "         [-1206708440228023]]), 90186173820: tensor(0), 91222152435: tensor([[835546980458838270],\n",
              "         [844802247661738020],\n",
              "         [833098173090412709],\n",
              "         [837838895663479858],\n",
              "         [831921418335301758],\n",
              "         [833075213112805506],\n",
              "         [839654837679160255],\n",
              "         [837321475037672069]])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdqiNR6Iyg9-",
        "colab_type": "text"
      },
      "source": [
        "and as you can see, Bob now has one of the shares of x! Furthermore, we can still call addition in this state, and PySyft will automatically perform the remote execution for us!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1uUOV3Fyg9_",
        "colab_type": "code",
        "outputId": "c73f77a9-63a8-48ff-dcf5-4b490d99c2d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "y = x + x\n",
        "y"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[AdditiveSharingTensor]\n",
              "\t-> (Wrapper)>[PointerTensor | me:3163214376 -> bob:99016654489]\n",
              "\t-> (Wrapper)>[PointerTensor | me:73455844056 -> alice:46104448810]\n",
              "\t-> (Wrapper)>[PointerTensor | me:93497503933 -> secure_worker:45364164014]\n",
              "\t*crypto provider: me*"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k__hFBeNYBB1",
        "colab_type": "code",
        "outputId": "7db3510f-fd7d-4de4-94d9-cc0d735990bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "bob._objects # bob has another tensor.. why?"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4164730689: tensor([[0., 0.],\n",
              "         [0., 1.]], requires_grad=True), 4556527595: tensor([[ 0.0511],\n",
              "         [-0.0198]], grad_fn=<AddmmBackward>), 20126619949: tensor([[1830708002507383895, 2263355130074537947]]), 21454551104: tensor([[4138977751660586335, 4129090394376407639],\n",
              "         [4130005867379347301, 4129428666750119995],\n",
              "         [4127893465457949495, 4125843393955993374],\n",
              "         [4139638634608415281, 4139151011653310749],\n",
              "         [4136304007953457938, 4127915038176218860],\n",
              "         [4125936806126740287, 4130400670610510207],\n",
              "         [4123456255369926993, 4132414902996903383],\n",
              "         [4138374107712638589, 4122947590620096571]]), 22229319681: tensor([[1167261756756035735],\n",
              "         [1167261756756035735],\n",
              "         [1167261756756035735],\n",
              "         [1167261756756035735],\n",
              "         [1167261756756035735],\n",
              "         [1167261756756035735],\n",
              "         [1167261756756035735],\n",
              "         [1167261756756035735]]), 24270442513: tensor([3018033052193549522, 4238951692305445015, 1378017496896172764,\n",
              "         3921585209512839588, 2721505074533999126]), 27063789006: tensor([-8000323665152941625]), 31797131174: tensor([[1075561881784774437],\n",
              "         [1084421667867912661],\n",
              "         [1084093641836640355],\n",
              "         [1071216563402263635],\n",
              "         [1075243568511233074],\n",
              "         [1079617576090895477],\n",
              "         [1079090002064313480],\n",
              "         [1080511751537061696]]), 33283181215: tensor([[-4968919904687818],\n",
              "         [ 8179295756518900],\n",
              "         [-3134104964202896],\n",
              "         [ 6226477353067388],\n",
              "         [ 8238888207129761],\n",
              "         [ 3959792395649463],\n",
              "         [ 8876724720437457],\n",
              "         [ 1307909944174353]]), 35324654758: tensor([[ 2406647636213275],\n",
              "         [-6453138446924949],\n",
              "         [-6125112415652643],\n",
              "         [ 6751966018724077],\n",
              "         [ 2724960909754638],\n",
              "         [-1649046669907765],\n",
              "         [-1121472643325768],\n",
              "         [-2543222116073984]]), 41250558902: tensor([[1830708002507383895],\n",
              "         [2263355130074537947]]), 41400850452: tensor([[  722019491897245640],\n",
              "         [ -852744589251803703],\n",
              "         [-3712053607542031584],\n",
              "         [-1567123816184368635],\n",
              "         [-3749442765269358833],\n",
              "         [  768037307751917480],\n",
              "         [-1633828678981129684],\n",
              "         [-2783480848929440830]]), 46567516546: tensor([[2377595232200136601, 2383638913840214287]]), 48492103601: tensor(28686063508086608), 53993437178: tensor([[-2406647636213275],\n",
              "         [ 6453138446924949],\n",
              "         [ 6125112415652643],\n",
              "         [-6751966018724077],\n",
              "         [-2724960909754638],\n",
              "         [ 1649046669907765],\n",
              "         [ 1121472643325768],\n",
              "         [ 2543222116073984]]), 58294597551: tensor([[1160108549806805032],\n",
              "         [1168968335889943256],\n",
              "         [1168640309858670950],\n",
              "         [1155763231424294230],\n",
              "         [1159790236533263669],\n",
              "         [1164164244112926072],\n",
              "         [1163636670086344075],\n",
              "         [1165058419559092291]]), 58423203506: tensor([[ 113527488561592630],\n",
              "         [1697546836913541723],\n",
              "         [4545151780632444293],\n",
              "         [2404962711847848493],\n",
              "         [4581364183604660591],\n",
              "         [  65037905360888026],\n",
              "         [2473483516660289939],\n",
              "         [3620802323967112899]]), 60174782169: tensor([[2496746663609287623],\n",
              "         [2487886877526149399],\n",
              "         [2488214903557421705],\n",
              "         [2501091981991798425],\n",
              "         [2497064976882828986],\n",
              "         [2492690969303166583],\n",
              "         [2493218543329748580],\n",
              "         [2491796793857000364]]), 66592158855: tensor([[ 7695031216954171],\n",
              "         [ -814370862423898],\n",
              "         [ 6493692087820905],\n",
              "         [ 3918782894947249],\n",
              "         [-7091114538005499],\n",
              "         [ 7588939351672908],\n",
              "         [ 1153940259685578],\n",
              "         [ 2925409132241462]]), 67349719825: tensor([[0.],\n",
              "         [0.]], requires_grad=True), 71302348306: tensor([2767404076142673010]), 72282334347: tensor([-7590213085410133677]), 74625618992: tensor([[3026230820672660937, 1013596260204113621],\n",
              "         [ 643283243862676468, 2046198317112848842],\n",
              "         [ 685795807377056590, 4100106974728583742],\n",
              "         [  76201530225555387,   52693750533038325],\n",
              "         [3852938711342070660, 3883829329333090197],\n",
              "         [1992683357071249859, 4394748627340567500],\n",
              "         [ 879880565724304350, 2724541129489391678],\n",
              "         [4367236917765869979, 3401196937300952730]]), 79062614970: tensor([[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         [0],\n",
              "         [0],\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]]), 88064707184: tensor([[ 1444038983794491280],\n",
              "         [-1705489178503607406],\n",
              "         [-7424107215084063168],\n",
              "         [-3134247632368737270],\n",
              "         [-7498885530538717666],\n",
              "         [ 1536074615503834960],\n",
              "         [-3267657357962259368],\n",
              "         [-5566961697858881660]]), 88379987850: tensor([[-2981203019061822],\n",
              "         [ 6274064183837928],\n",
              "         [-5430010387487383],\n",
              "         [ -689287814420234],\n",
              "         [-6606765142598334],\n",
              "         [-5452970365094586],\n",
              "         [ 1126654201260163],\n",
              "         [-1206708440228023]]), 90186173820: tensor(0), 91222152435: tensor([[835546980458838270],\n",
              "         [844802247661738020],\n",
              "         [833098173090412709],\n",
              "         [837838895663479858],\n",
              "         [831921418335301758],\n",
              "         [833075213112805506],\n",
              "         [839654837679160255],\n",
              "         [837321475037672069]]), 99016654489: tensor([6036066104387099044, 8477903384610890030, 2756034993792345528,\n",
              "         7843170419025679176, 5443010149067998252])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGsYMXopyg-C",
        "colab_type": "code",
        "outputId": "90f1edd9-07a7-4d62-ec69-476e8e183a29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.get() # notice that we have doubled the values on each worker!"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2,  4,  6,  8, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AErqHN8Sf1PF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCTEsZOYyg-E",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Fixed Precision using PySyft\n",
        "\n",
        "We can also convert a tensor to fixed precision using `.fix_precision()`\n",
        "This is important when doing FL since the values you are sharing are decimal numbers.\n",
        "\n",
        "**Q: what values are we sharing? what are the shared secretes?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX4BjzDjyg-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = th.tensor([0.1, 0.2, 0.3, 0.4]) # a decimal tensor!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFDXAJOcyg-J",
        "colab_type": "code",
        "outputId": "87823918-9568-4df5-8284-e0873dc198af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1000, 0.2000, 0.3000, 0.4000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2G36bvmyg-M",
        "colab_type": "code",
        "outputId": "25423f04-9567-498f-8c5d-9e746a371ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = x.fix_prec() # call this function to encode the decimal tensor using fixed precision\n",
        "x # notice that this is a tensor chain <-------"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>FixedPrecisionTensor>tensor([100, 200, 300, 400])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATcM3Xivad5x",
        "colab_type": "code",
        "outputId": "0b564bbb-1667-4d0d-8782-0ba1790bee1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(f'Type of x {type(x)}')\n",
        "print(f'Type of x.child {type(x.child)}')\n",
        "print(f'Type of x.child.child {type(x.child.child)}') # <-- this is how you get the data from a fixed precision tensor"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type of x <class 'syft.frameworks.torch.tensors.interpreters.native.Tensor'>\n",
            "Type of x.child <class 'syft.frameworks.torch.tensors.interpreters.precision.FixedPrecisionTensor'>\n",
            "Type of x.child.child <class 'syft.frameworks.torch.tensors.interpreters.native.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUoWTR0zaGGc",
        "colab_type": "code",
        "outputId": "6ced315a-08b8-4676-e877-2c4d9ee85f6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# to decode the previous tensor\n",
        "print(x.float_prec())"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.1000, 0.2000, 0.3000, 0.4000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxhTUS0fyg-Q",
        "colab_type": "code",
        "outputId": "8697843c-e85e-4205-93ff-5839ee1d7618",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = x + x\n",
        "y"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>FixedPrecisionTensor>tensor([200, 400, 600, 800])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1zowAiNyg-S",
        "colab_type": "code",
        "outputId": "94939d59-be9f-45d4-8f51-54ab9907005b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = y.float_prec()\n",
        "y"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2000, 0.4000, 0.6000, 0.8000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD3PxBYtyg-T",
        "colab_type": "text"
      },
      "source": [
        "### Shared Fixed Precision\n",
        "\n",
        "And of course, we can combine the two!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHvWTMsCyg-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = th.tensor([0.1, 0.2, 0.3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJdZTTsMyg-V",
        "colab_type": "code",
        "outputId": "a1fe9593-f0cd-4829-b9e5-0bcbddbf4eef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "x = x.fix_prec().share(bob, alice)\n",
        "x"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
              "\t-> (Wrapper)>[PointerTensor | me:99930901324 -> bob:74491913464]\n",
              "\t-> (Wrapper)>[PointerTensor | me:23951281280 -> alice:13683868331]\n",
              "\t*crypto provider: me*"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwuwrFRVbiQD",
        "colab_type": "code",
        "outputId": "34fc1be6-a2e1-4915-a84b-efb24f53fc9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4164730689: tensor([[0., 0.],\n",
              "         [0., 1.]], requires_grad=True), 4556527595: tensor([[ 0.0511],\n",
              "         [-0.0198]], grad_fn=<AddmmBackward>), 20126619949: tensor([[1830708002507383895, 2263355130074537947]]), 21454551104: tensor([[4138977751660586335, 4129090394376407639],\n",
              "         [4130005867379347301, 4129428666750119995],\n",
              "         [4127893465457949495, 4125843393955993374],\n",
              "         [4139638634608415281, 4139151011653310749],\n",
              "         [4136304007953457938, 4127915038176218860],\n",
              "         [4125936806126740287, 4130400670610510207],\n",
              "         [4123456255369926993, 4132414902996903383],\n",
              "         [4138374107712638589, 4122947590620096571]]), 22229319681: tensor([[1167261756756035735],\n",
              "         [1167261756756035735],\n",
              "         [1167261756756035735],\n",
              "         [1167261756756035735],\n",
              "         [1167261756756035735],\n",
              "         [1167261756756035735],\n",
              "         [1167261756756035735],\n",
              "         [1167261756756035735]]), 24270442513: tensor([3018033052193549522, 4238951692305445015, 1378017496896172764,\n",
              "         3921585209512839588, 2721505074533999126]), 27063789006: tensor([-8000323665152941625]), 31797131174: tensor([[1075561881784774437],\n",
              "         [1084421667867912661],\n",
              "         [1084093641836640355],\n",
              "         [1071216563402263635],\n",
              "         [1075243568511233074],\n",
              "         [1079617576090895477],\n",
              "         [1079090002064313480],\n",
              "         [1080511751537061696]]), 33283181215: tensor([[-4968919904687818],\n",
              "         [ 8179295756518900],\n",
              "         [-3134104964202896],\n",
              "         [ 6226477353067388],\n",
              "         [ 8238888207129761],\n",
              "         [ 3959792395649463],\n",
              "         [ 8876724720437457],\n",
              "         [ 1307909944174353]]), 35324654758: tensor([[ 2406647636213275],\n",
              "         [-6453138446924949],\n",
              "         [-6125112415652643],\n",
              "         [ 6751966018724077],\n",
              "         [ 2724960909754638],\n",
              "         [-1649046669907765],\n",
              "         [-1121472643325768],\n",
              "         [-2543222116073984]]), 41250558902: tensor([[1830708002507383895],\n",
              "         [2263355130074537947]]), 41400850452: tensor([[  722019491897245640],\n",
              "         [ -852744589251803703],\n",
              "         [-3712053607542031584],\n",
              "         [-1567123816184368635],\n",
              "         [-3749442765269358833],\n",
              "         [  768037307751917480],\n",
              "         [-1633828678981129684],\n",
              "         [-2783480848929440830]]), 46567516546: tensor([[2377595232200136601, 2383638913840214287]]), 48492103601: tensor(28686063508086608), 53993437178: tensor([[-2406647636213275],\n",
              "         [ 6453138446924949],\n",
              "         [ 6125112415652643],\n",
              "         [-6751966018724077],\n",
              "         [-2724960909754638],\n",
              "         [ 1649046669907765],\n",
              "         [ 1121472643325768],\n",
              "         [ 2543222116073984]]), 58294597551: tensor([[1160108549806805032],\n",
              "         [1168968335889943256],\n",
              "         [1168640309858670950],\n",
              "         [1155763231424294230],\n",
              "         [1159790236533263669],\n",
              "         [1164164244112926072],\n",
              "         [1163636670086344075],\n",
              "         [1165058419559092291]]), 58423203506: tensor([[ 113527488561592630],\n",
              "         [1697546836913541723],\n",
              "         [4545151780632444293],\n",
              "         [2404962711847848493],\n",
              "         [4581364183604660591],\n",
              "         [  65037905360888026],\n",
              "         [2473483516660289939],\n",
              "         [3620802323967112899]]), 60174782169: tensor([[2496746663609287623],\n",
              "         [2487886877526149399],\n",
              "         [2488214903557421705],\n",
              "         [2501091981991798425],\n",
              "         [2497064976882828986],\n",
              "         [2492690969303166583],\n",
              "         [2493218543329748580],\n",
              "         [2491796793857000364]]), 66592158855: tensor([[ 7695031216954171],\n",
              "         [ -814370862423898],\n",
              "         [ 6493692087820905],\n",
              "         [ 3918782894947249],\n",
              "         [-7091114538005499],\n",
              "         [ 7588939351672908],\n",
              "         [ 1153940259685578],\n",
              "         [ 2925409132241462]]), 67349719825: tensor([[0.],\n",
              "         [0.]], requires_grad=True), 71302348306: tensor([2767404076142673010]), 72282334347: tensor([-7590213085410133677]), 74491913464: tensor([4449185470908418844, 4297919281496595671, 1641913792364535471]), 74625618992: tensor([[3026230820672660937, 1013596260204113621],\n",
              "         [ 643283243862676468, 2046198317112848842],\n",
              "         [ 685795807377056590, 4100106974728583742],\n",
              "         [  76201530225555387,   52693750533038325],\n",
              "         [3852938711342070660, 3883829329333090197],\n",
              "         [1992683357071249859, 4394748627340567500],\n",
              "         [ 879880565724304350, 2724541129489391678],\n",
              "         [4367236917765869979, 3401196937300952730]]), 79062614970: tensor([[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         [0],\n",
              "         [0],\n",
              "         [0],\n",
              "         [0],\n",
              "         [0]]), 88064707184: tensor([[ 1444038983794491280],\n",
              "         [-1705489178503607406],\n",
              "         [-7424107215084063168],\n",
              "         [-3134247632368737270],\n",
              "         [-7498885530538717666],\n",
              "         [ 1536074615503834960],\n",
              "         [-3267657357962259368],\n",
              "         [-5566961697858881660]]), 88379987850: tensor([[-2981203019061822],\n",
              "         [ 6274064183837928],\n",
              "         [-5430010387487383],\n",
              "         [ -689287814420234],\n",
              "         [-6606765142598334],\n",
              "         [-5452970365094586],\n",
              "         [ 1126654201260163],\n",
              "         [-1206708440228023]]), 90186173820: tensor(0), 91222152435: tensor([[835546980458838270],\n",
              "         [844802247661738020],\n",
              "         [833098173090412709],\n",
              "         [837838895663479858],\n",
              "         [831921418335301758],\n",
              "         [833075213112805506],\n",
              "         [839654837679160255],\n",
              "         [837321475037672069]])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUwsGFb3yg-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = x + x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCzDtdYcyg-a",
        "colab_type": "code",
        "outputId": "1d9467fa-d102-47fe-9542-8d29cec46af8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.get().float_prec()"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2000, 0.4000, 0.6000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLTpJ64Syg-e",
        "colab_type": "text"
      },
      "source": [
        "# Final Project: Federated Learning with Encrypted Gradient Aggregation\n",
        "\n",
        "Reuse your project from the Secuered Agggregator above to train the same model using the FL appraoch, but this time use the Additive Sharing Encryption so that the participating members have access to their own models only. There is no secure aggregator in this senario. \n",
        "Include four members in this project (Alice, Bob, Ted, and Carol). \n",
        "\n",
        "Hint: we will *share* the model with the shareholders, do addition on the encrypted models, and then aggregate the final model locally. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLLBiEksHpn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "def test_network(net, trainloader):\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "    dataiter = iter(trainloader)\n",
        "    images, labels = dataiter.next()\n",
        "\n",
        "    # Create Variables for the inputs and targets\n",
        "    inputs = Variable(images)\n",
        "    targets = Variable(images)\n",
        "\n",
        "    # Clear the gradients from all Variables\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass, then backward pass, then update weights\n",
        "    output = net.forward(inputs)\n",
        "    loss = criterion(output, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def imshow(image, ax=None, title=None, normalize=True):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "\n",
        "    if normalize:\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        image = std * image + mean\n",
        "        image = np.clip(image, 0, 1)\n",
        "\n",
        "    ax.imshow(image)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    ax.spines['bottom'].set_visible(False)\n",
        "    ax.tick_params(axis='both', length=0)\n",
        "    ax.set_xticklabels('')\n",
        "    ax.set_yticklabels('')\n",
        "\n",
        "    return ax\n",
        "\n",
        "\n",
        "def view_recon(img, recon):\n",
        "    ''' Function for displaying an image (as a PyTorch Tensor) and its\n",
        "        reconstruction also a PyTorch Tensor\n",
        "    '''\n",
        "\n",
        "    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n",
        "    axes[0].imshow(img.numpy().squeeze())\n",
        "    axes[1].imshow(recon.data.numpy().squeeze())\n",
        "    for ax in axes:\n",
        "        ax.axis('off')\n",
        "        ax.set_adjustable('box-forced')\n",
        "\n",
        "def view_classify(img, ps, version=\"MNIST\"):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    if version == \"MNIST\":\n",
        "        ax2.set_yticklabels(np.arange(10))\n",
        "    elif version == \"Fashion\":\n",
        "        ax2.set_yticklabels(['T-shirt/top',\n",
        "                            'Trouser',\n",
        "                            'Pullover',\n",
        "                            'Dress',\n",
        "                            'Coat',\n",
        "                            'Sandal',\n",
        "                            'Shirt',\n",
        "                            'Sneaker',\n",
        "                            'Bag',\n",
        "                            'Ankle Boot'], size='small');\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdT8YJBxI0Wq",
        "colab_type": "code",
        "outputId": "509bafd1-7c5f-482e-8f83-a2d04d127b63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        }
      },
      "source": [
        "!pip install syft"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: syft in /usr/local/lib/python3.6/dist-packages (0.1.21a1)\n",
            "Requirement already satisfied: tf-encrypted>=0.5.4 in /usr/local/lib/python3.6/dist-packages (from syft) (0.5.6)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.0)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.3.0)\n",
            "Requirement already satisfied: websocket-client>=0.56.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.56.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.16.4)\n",
            "Requirement already satisfied: flask-socketio>=3.3.2 in /usr/local/lib/python3.6/dist-packages (from syft) (4.1.0)\n",
            "Requirement already satisfied: msgpack>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from syft) (0.6.1)\n",
            "Requirement already satisfied: lz4>=2.1.6 in /usr/local/lib/python3.6/dist-packages (from syft) (2.1.10)\n",
            "Requirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.1)\n",
            "Requirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Requirement already satisfied: zstd>=1.4.0.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0.0)\n",
            "Requirement already satisfied: websockets>=7.0 in /usr/local/lib/python3.6/dist-packages (from syft) (8.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.21.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (5.1.1)\n",
            "Requirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (4.3.0)\n",
            "Requirement already satisfied: python-socketio>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from flask-socketio>=3.3.2->syft) (4.2.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (0.15.4)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (7.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (2.10.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (0.13.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.1.7)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.2.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.0.8)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.11.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.33.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.8.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.7.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->syft) (0.46)\n",
            "Requirement already satisfied: python-engineio>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from python-socketio>=2.1.0->flask-socketio>=3.3.2->syft) (3.8.2.post1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=1.0.2->syft) (1.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (41.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSmcZYzYyg-g",
        "colab_type": "code",
        "outputId": "49a6e8c9-7d78-42c8-afb0-5654be36a9bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# create cells as needed. Separate your solution into logical cells.\n",
        "import syft as sy\n",
        "import torch as th\n",
        "from torch import nn, optim\n",
        "\n",
        "hook = sy.TorchHook(th)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0714 16:28:39.227456 140425218107264 hook.py:98] Torch was already hooked... skipping hooking process\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1z83Z2vHCNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
        "ted = sy.VirtualWorker(hook, id=\"ted\")\n",
        "carol = sy.VirtualWorker(hook, id=\"carol\")\n",
        "crypto_provider = sy.VirtualWorker(id=\"crypto_provider\", hook=hook)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qGjePOGHJAm",
        "colab_type": "code",
        "outputId": "802c955f-2a31-467d-853a-c7dfcc286f8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob.clear_objects()\n",
        "ted.clear_objects()\n",
        "alice.clear_objects()\n",
        "carol.clear_objects()"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:carol #objects:0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilHmisWbHLA7",
        "colab_type": "code",
        "outputId": "8bc0cea9-0f8c-4f3e-8f1d-c6ebaa08aa50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# Clear workers if previously holding any values\n",
        "print(bob._objects)\n",
        "print(alice._objects)\n",
        "print(ted._objects)\n",
        "print(carol._objects)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AdNcaGAHPlr",
        "colab_type": "code",
        "outputId": "dc5ccd81-8202-40bf-fca6-e0e14230f480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "# A Toy Dataset\n",
        "data = th.tensor([[0,0],[0,1],[1,0],[1,1.],[0,0],[1,1],[0,1],[1,1.]], requires_grad=True)\n",
        "target = th.tensor([[0],[0],[1],[1.],[0],[0],[1],[1.]], requires_grad=True)\n",
        "\n",
        "# get pointers to training data on each worker by\n",
        "# sending some training data to bob and alice\n",
        "data = data.fix_precision().share(bob, alice, ted, carol, crypto_provider=crypto_provider,  requires_grad=True)\n",
        "target = target.fix_precision().share(bob, alice, ted, carol, crypto_provider=crypto_provider,  requires_grad=True)\n",
        "print(bob._objects)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{15703967801: tensor([[1328031935904318588, 3684552063509957971],\n",
            "        [ 903783791522674295, 2423581070562498429],\n",
            "        [  60980386783572727, 4417700897477477905],\n",
            "        [1497855390513288654, 1368097050863192840],\n",
            "        [ 838584950272227952, 2891016758980196732],\n",
            "        [3236489687029233973, 3621684913487369611],\n",
            "        [2843526574409667546, 1596477951655862390],\n",
            "        [ 286927295796001055, 2027484301335925692]]), 15550388343: tensor([[3684007204458618157],\n",
            "        [ 643258595403534827],\n",
            "        [2988626985222028154],\n",
            "        [3123876605441354964],\n",
            "        [3371536714130295103],\n",
            "        [3500211536003448418],\n",
            "        [1741286689387080877],\n",
            "        [3809397601451440112]])}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaYous0sHVKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "model = nn.Linear(2,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9AXI4tLJMbq",
        "colab_type": "text"
      },
      "source": [
        "[link text](https://)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM2x1h5iHZam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.fix_precision().share(bob, alice, ted, carol, crypto_provider=crypto_provider,  requires_grad=True)\n",
        "opt = optim.SGD(params=model.parameters(), lr=0.1).fix_precision()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inlkI5W_HcZ4",
        "colab_type": "code",
        "outputId": "03a8a796-59f6-4d5d-a075-b0ed489c7774",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "print(model.weight)\n",
        "print(opt)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter>AutogradTensor>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
            "\t-> (Wrapper)>[PointerTensor | me:72221954693 -> bob:98936011325]\n",
            "\t-> (Wrapper)>[PointerTensor | me:69834504128 -> alice:80299507996]\n",
            "\t-> (Wrapper)>[PointerTensor | me:18344317846 -> ted:78521713411]\n",
            "\t-> (Wrapper)>[PointerTensor | me:84732041413 -> carol:63877723060]\n",
            "\t*crypto provider: crypto_provider*\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: FixedPrecisionTensor>tensor([100])\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btZmL2ghHhXV",
        "colab_type": "code",
        "outputId": "c740d75a-962c-48ab-eb5d-df09f686c6ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "    # Train Model'S\n",
        "    opt.zero_grad()\n",
        "    pred = model(data)\n",
        "    loss = ((pred - target)**2).sum()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    print(F'loss {loss.get().float_precision()}')"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-143-62821486745e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mF'loss {loss.get().float_precision()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    683\u001b[0m                 \u001b[0;31m# Put back the wrappers where needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m                 response = syft.frameworks.torch.hook_args.hook_response(\n\u001b[0;32m--> 685\u001b[0;31m                     \u001b[0mmethod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_self\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36mhook_response\u001b[0;34m(attr, response, wrap_type, wrap_args, new_self)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mresponse_hook_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_method_response_functions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;31m# Try running it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mnew_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse_hook_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Update the function in cas of an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmany_fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36mtwo_fold\u001b[0;34m(lambdas, args, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtwo_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# if the rule is a list or tuple.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;31m# Last if not, rule is probably == 1 so use type to return the right transformation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m         \u001b[0;32melse\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbackward_func\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwrap_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mwrap_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# And do this for all the responses / rules provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     ]\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     70\u001b[0m backward_func = {\n\u001b[1;32m     71\u001b[0m     \u001b[0mTorchTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mPointerTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'wrap'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD-fgEv4Jj1y",
        "colab_type": "code",
        "outputId": "5ed2adbb-b89a-4d3d-9fc2-8972282ae251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "model.weight"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "Parameter>AutogradTensor>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
              "\t-> (Wrapper)>[PointerTensor | me:72221954693 -> bob:98936011325]\n",
              "\t-> (Wrapper)>[PointerTensor | me:69834504128 -> alice:80299507996]\n",
              "\t-> (Wrapper)>[PointerTensor | me:18344317846 -> ted:78521713411]\n",
              "\t-> (Wrapper)>[PointerTensor | me:84732041413 -> carol:63877723060]\n",
              "\t*crypto provider: crypto_provider*"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAsKarLKJh4f",
        "colab_type": "code",
        "outputId": "e118b8c1-947e-4845-9e5a-69be8957e044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#aggregated model \n",
        "model = model.get()\n",
        "print(model.float_precision().weight)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0850, -0.0510]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}