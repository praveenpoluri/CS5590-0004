{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LabIIMembership Attack -dataset change solution guidelines 1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveenpoluri/CS5590-0004/blob/master/LabII/LabIIMembership_Attack_dataset_change_solution_guidelines_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvK6LaVhrfZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# required imports\n",
        "import sys \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision \n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O05dkTKAsEh-",
        "colab_type": "code",
        "outputId": "94957537-5066-4b91-871d-ae24115ec1a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# mount the google drive to download the datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "project_path = '/content/drive/My Drive/cybersecurity'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEW1mLverl7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create transforms to load the images, nothing much is needed here. \n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Normalize the test set same as training set without augmentation\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjsFJTFwr1wV",
        "colab_type": "code",
        "outputId": "e0a6f889-72be-49f3-94b1-3cb8d2cc3abc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# download CIFAR 10 training set\n",
        "trainset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "\n",
        "# load the trainning set\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "\n",
        "# download the test data\n",
        "testset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=False,\n",
        "                                        download=True, transform=transform_test)\n",
        "\n",
        "# load the test data\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "# check those manually on the dataset site: https://www.cs.toronto.edu/~kriz/cifar.html"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itY7G_y3tDnC",
        "colab_type": "code",
        "outputId": "790f3906-ce42-4665-8ac9-b0cc71e118d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "# helper function to unnormalize and plot image \n",
        "def imshow(img):\n",
        "    img = np.array(img)\n",
        "    img = img / 2 + 0.5\n",
        "    img = np.moveaxis(img, 0, -1)\n",
        "    plt.imshow(img)\n",
        "    \n",
        "# display sample from dataset \n",
        "imgs, labels = iter(trainloader).next()\n",
        "imshow(torchvision.utils.make_grid(imgs)) \n",
        "\n",
        "# notice who we converted the class idx to labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "# run this cell multiple times and notice diff images"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " frog   car  bird horse\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDAwMRgjMC93AwMBghMC80A0MDAxGCP4/ATGQuWFpavoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJK32k42gbEK",
        "colab_type": "code",
        "outputId": "c275b7e1-3d4e-4408-88d3-b84c9527c158",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# divide the training dataset into the required groups Make sure they are balanced\n",
        "# original trainset is made of 50k images\n",
        "\n",
        "total_size = len(trainset)\n",
        "split1 = total_size // 4\n",
        "split2 = split1 * 2\n",
        "split3 = split1 * 3\n",
        "\n",
        "print(total_size, split1, split2, split3)\n",
        "\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "shadow_train_idx = indices[:split1]\n",
        "shadow_out_idx = indices[split1:split2]\n",
        "\n",
        "# two groups to train the Target (in and out)\n",
        "target_train_idx = indices[split2:split3]\n",
        "target_out_idx =  indices[split3:]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 12500 25000 37500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4wJ_0lkhp76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj9LuQJNuCXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# create a CNN\n",
        "# Input shape (3, 32, 32) \n",
        "# architecture: simple. 2 conv and 2 Max pool, followed by 2 fc (120, 84) \n",
        "# output of fc is 10 because we have 10 classes!\n",
        "\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        \n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "        \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O39H-xzClPgh",
        "colab_type": "code",
        "outputId": "246000b4-9fc3-4905-a84a-137706d0977c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# check if CUDA available or not\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER_B4V8YjKyU",
        "colab_type": "code",
        "outputId": "984951a4-ff6a-406c-e7cb-b4dc1e48f5d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# initalize a target model and train it\n",
        "\n",
        "target_model = CNN()\n",
        "taget_model = target_model.cuda()\n",
        "criterion = nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "optimizer = optim.Adam(target_model.parameters(), lr=0.0003) # try Adam VS SGD\n",
        "\n",
        "    \n",
        "epochs = 20\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in target_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        logits = target_model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(\"\\nEpoch : {}/{}..\".format(e+1,epochs),f\"Training loss: {running_loss/len(target_train_loader)}\")\n",
        "\n",
        "#save the model\n",
        "print(\"Model: \\n\\n\", target_model, '\\n')\n",
        "torch.save(target_model.state_dict(), project_path+'/target_checkpoint.pth')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 1/20.. Training loss: 1.7584894878022812\n",
            "\n",
            "Epoch : 2/20.. Training loss: 1.4398618028749286\n",
            "\n",
            "Epoch : 3/20.. Training loss: 1.2446832133985846\n",
            "\n",
            "Epoch : 4/20.. Training loss: 1.1145704361178992\n",
            "\n",
            "Epoch : 5/20.. Training loss: 1.0179457894104826\n",
            "\n",
            "Epoch : 6/20.. Training loss: 0.9420192292736619\n",
            "\n",
            "Epoch : 7/20.. Training loss: 0.8687216844362067\n",
            "\n",
            "Epoch : 8/20.. Training loss: 0.8214973922428268\n",
            "\n",
            "Epoch : 9/20.. Training loss: 0.7671693013718975\n",
            "\n",
            "Epoch : 10/20.. Training loss: 0.7185524099261102\n",
            "\n",
            "Epoch : 11/20.. Training loss: 0.6777689084791771\n",
            "\n",
            "Epoch : 12/20.. Training loss: 0.6451435598933026\n",
            "\n",
            "Epoch : 13/20.. Training loss: 0.6160544495067328\n",
            "\n",
            "Epoch : 14/20.. Training loss: 0.584836756053102\n",
            "\n",
            "Epoch : 15/20.. Training loss: 0.5547972078842428\n",
            "\n",
            "Epoch : 16/20.. Training loss: 0.5318351630216746\n",
            "\n",
            "Epoch : 17/20.. Training loss: 0.4951695369251663\n",
            "\n",
            "Epoch : 18/20.. Training loss: 0.48259905952474347\n",
            "\n",
            "Epoch : 19/20.. Training loss: 0.4543237695732461\n",
            "\n",
            "Epoch : 20/20.. Training loss: 0.43789969824368846\n",
            "Model: \n",
            "\n",
            " CNN(\n",
            "  (conv_layer): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Dropout2d(p=0.05)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Dropout(p=0.1)\n",
            "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.1)\n",
            "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (7): LogSoftmax()\n",
            "  )\n",
            ") \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpY8ktdskRQN",
        "colab_type": "code",
        "outputId": "01f77201-11a0-4a24-ce55-7a531eb6b4f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the accuracy of the Target Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = target_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 12500 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 77 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEClKFqikmUl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha_VqRVVkoCm",
        "colab_type": "code",
        "outputId": "5e92960e-b9fe-440d-e8f8-1d0375db3bfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# initalize a Shadow Model and Train it\n",
        "# for the first ICP, your shadow model can have the same CNN architecture and hyperparameters\n",
        "\n",
        "shadow_model = CNN()\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()\n",
        "#send to GPU\n",
        "shadow_model = shadow_model.cuda()\n",
        "shadow_criterion =  nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "shadow_optimizer = optim.Adam(shadow_model.parameters(), lr=0.0003) # ADAM \n",
        "\n",
        "\n",
        "# let the magic begin\n",
        "epochs = 20\n",
        "with torch.set_grad_enabled(True):\n",
        "  for e in range(epochs):\n",
        "      running_loss = 0\n",
        "      for images, labels in shadow_train_loader:\n",
        "          # sending tensors to GPU\n",
        "          images = images.cuda()\n",
        "          labels = labels.cuda()\n",
        "          shadow_optimizer.zero_grad()\n",
        "          logits = shadow_model(images)\n",
        "          shadow_loss = shadow_criterion(logits, labels)\n",
        "          shadow_loss.backward()\n",
        "          shadow_optimizer.step()\n",
        "\n",
        "\n",
        "          running_loss += shadow_loss.item()\n",
        "      else:\n",
        "          print(\"\\nEpoch : {}/{}..\".format(e+1,epochs),f\"Training loss: {running_loss/len(shadow_train_loader)}\")\n",
        "\n",
        "#save the model\n",
        "print(\"Our model: \\n\\n\", shadow_model, '\\n')\n",
        "torch.save(shadow_model.state_dict(), project_path+'/shadow_checkpoint.pth')\n",
        "print('Finished Training the Shadow model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 1/20.. Training loss: 1.8152915897881587\n",
            "\n",
            "Epoch : 2/20.. Training loss: 1.4869877214322005\n",
            "\n",
            "Epoch : 3/20.. Training loss: 1.3030839470951148\n",
            "\n",
            "Epoch : 4/20.. Training loss: 1.1851700192979535\n",
            "\n",
            "Epoch : 5/20.. Training loss: 1.0905567648465677\n",
            "\n",
            "Epoch : 6/20.. Training loss: 1.007945784179451\n",
            "\n",
            "Epoch : 7/20.. Training loss: 0.9269451595404569\n",
            "\n",
            "Epoch : 8/20.. Training loss: 0.8852235023932689\n",
            "\n",
            "Epoch : 9/20.. Training loss: 0.826741272626478\n",
            "\n",
            "Epoch : 10/20.. Training loss: 0.7707388960491971\n",
            "\n",
            "Epoch : 11/20.. Training loss: 0.719840779424171\n",
            "\n",
            "Epoch : 12/20.. Training loss: 0.7001564950132004\n",
            "\n",
            "Epoch : 13/20.. Training loss: 0.6560657263669135\n",
            "\n",
            "Epoch : 14/20.. Training loss: 0.6288866145950754\n",
            "\n",
            "Epoch : 15/20.. Training loss: 0.6087105634534146\n",
            "\n",
            "Epoch : 16/20.. Training loss: 0.5696254600687405\n",
            "\n",
            "Epoch : 17/20.. Training loss: 0.5456405857392131\n",
            "\n",
            "Epoch : 18/20.. Training loss: 0.5213719619452344\n",
            "\n",
            "Epoch : 19/20.. Training loss: 0.49775030152143346\n",
            "\n",
            "Epoch : 20/20.. Training loss: 0.48102178511536103\n",
            "Our model: \n",
            "\n",
            " CNN(\n",
            "  (conv_layer): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Dropout2d(p=0.05)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Dropout(p=0.1)\n",
            "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.1)\n",
            "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (7): LogSoftmax()\n",
            "  )\n",
            ") \n",
            "\n",
            "Finished Training the Shadow model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0kP_-62ljFE",
        "colab_type": "code",
        "outputId": "55a2090c-f679-40bd-b7d1-eba2d3eac58c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the accuracy of the Shadow Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = shadow_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        #print(predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 12500 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 75 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ymKnj7QpdDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = CNN()\n",
        "    model.load_state_dict(checkpoint)\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J1B1OhMp6er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaD8_N34l3Eh",
        "colab_type": "code",
        "outputId": "81b49238-3e0a-462e-c1a1-07635d1585bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#load the model\n",
        "load_shadow_model = load_checkpoint(project_path+'/shadow_checkpoint.pth')\n",
        "load_shadow_model = load_shadow_model.cuda()\n",
        "\n",
        "# freeze the Shadow model \n",
        "for param in load_shadow_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "\n",
        "labels_0 = 0#np.zeros(1)\n",
        "labels_1 = 1#np.ones(1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "print(predictions[0])  \n",
        "print(predictions[17000])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([1.03256614e-04, 2.75987560e-07, 2.06277327e-04, 3.30030656e-04,\n",
            "       1.36835722e-03, 1.91890495e-03, 4.24083652e-07, 9.96042490e-01,\n",
            "       2.56733892e-06, 2.75278380e-05], dtype=float32), 1]\n",
            "[array([3.1399410e-02, 2.1190448e-05, 2.2439783e-02, 1.4885777e-01,\n",
            "       6.6391683e-01, 3.6686409e-02, 7.1530598e-03, 8.8585056e-02,\n",
            "       3.6914332e-04, 5.7121448e-04], dtype=float32), 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhaKjRRUl6Po",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a new dataset of the shape [predictions(shadow_in), 1], [predicitons(shadow_out), 0] and zip them together\n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/shadow.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl56BLIpl8Nl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the recall and precision of your attack network using the Target_out and Target_in datasets\n",
        "# to do so, take a random numer of datapoints, run them throw the target model,\n",
        "#load the model\n",
        "load_target_model = load_checkpoint(project_path+'/target_checkpoint.pth')\n",
        "load_target_model = load_target_model.cuda()\n",
        "\n",
        "# freeze the Shadow model \n",
        "for param in load_target_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "label_size = (1,1)\n",
        "\n",
        "labels_0 = 0\n",
        "labels_1 = 1\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/target.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yEnRcZW6sUY",
        "colab_type": "code",
        "outputId": "84c453c1-907e-4c02-a30a-520803e79b9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# check if CUDA available or not\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UZ2tfJzl94s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/shadow.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    predictionsList = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJFbXp8umAam",
        "colab_type": "code",
        "outputId": "44d4ce51-8f18-436a-8fd0-b9935b278c1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total_size = len(predictionsList)\n",
        "split1 = total_size // 4\n",
        "split1 = total_size - split1 \n",
        "split2 = split1*2\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "train_idx = indices[:] \n",
        "test_idx = indices[split1:] \n",
        "print(f'No.of train date {len(train_idx)} and No.of test data {len(test_idx)}')\n",
        "batch_size = 10 # pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "train_sampler = SubsetRandomSampler(train_idx) # Pytorch function\n",
        "train_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=train_sampler)\n",
        "\n",
        "test_sampler = SubsetRandomSampler(test_idx) # Pytorch function\n",
        "test_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=test_sampler)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No.of train date 25000 and No.of test data 6250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU012hhrmDvi",
        "colab_type": "code",
        "outputId": "857d5c49-47b7-4775-83e5-c4e9243c1369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# create the Attack Model: A NN binary classifier {0, 1}\n",
        "# the input to this model is the propability distribution vector of size 10\n",
        "# and the output is either 0 (input was not included in training) or 1\n",
        "from torch.autograd import Variable\n",
        "attack_model = nn.Sequential(nn.Linear(10, 20),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(20, 26),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(26, 16),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(16, 8),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(8, 2),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "attack_model = attack_model.cuda()\n",
        "attack_criterion = nn.CrossEntropyLoss()\n",
        "attack_optimizer = optim.Adam(attack_model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for outputs, labels in train_loader:\n",
        "        # sending tensors to GPU\n",
        "        outputs = outputs.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        attack_optimizer.zero_grad()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        #print(pred.data, labels)\n",
        "        loss = attack_criterion(pred, labels)\n",
        "        loss.backward()\n",
        "        attack_optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(predictionsList)}\")\n",
        "        \n",
        "torch.save(attack_model.state_dict(), project_path+'/attack_checkpoint.pth')\n",
        "print('Finished Training the Attack model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.06935151975631713\n",
            "Training loss: 0.06934330963373184\n",
            "Training loss: 0.06933639912128449\n",
            "Training loss: 0.06932635615348816\n",
            "Training loss: 0.06932766935825348\n",
            "Finished Training the Attack model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWR_CXQEmIC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/target.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    validation = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecc2gaFmHnoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1 # pick your own\n",
        "\n",
        "validation_sampler = SubsetRandomSampler(indices[6250:18250]) # randomly picking 5000 data items\n",
        "validation_loader = torch.utils.data.DataLoader(validation, batch_size=batch_size, sampler=validation_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haNVIg-FHsFv",
        "colab_type": "code",
        "outputId": "c80070f8-085d-4598-b250-e20e36160587",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "#input the output of the target model to your attack network \n",
        "# you already know the target_in and target_out samples, so use that info to evaluate the attack model\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "total = 0\n",
        "tp = 0\n",
        "tn = 0\n",
        "fp = 0\n",
        "fn = 0\n",
        "with torch.no_grad():\n",
        "    for outputs, labels in validation_loader:\n",
        "        # sending tensors to GPU\n",
        "        outputs = outputs.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        predicted = torch.argmax(pred.data)\n",
        "        #print('\\n',pred.data, predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted.item() == labels.item())\n",
        "        tp += ((predicted.item() == labels.item()) and (predicted.item() == 1))\n",
        "        tn += ((predicted.item() == labels.item()) and (predicted.item() == 0))\n",
        "        fp += ((predicted.item() != labels.item()) and (predicted.item() == 1))\n",
        "        fn += ((predicted.item() != labels.item()) and (predicted.item() == 0))\n",
        "        #print(predicted.item(),labels.item(),correct)\n",
        "incorrect = total- correct\n",
        "print(f'TP : {tp}, TN : {tn}, FP : {fp}, FN : {fn}')\n",
        "pre = tp/(tp+fp)\n",
        "rec = tp/(tp+fn)\n",
        "print(f'Precision {pre*100}')\n",
        "print(f'Recall {rec*100}')\n",
        "print(f'F1 Score {2*((pre*rec)/(pre+rec))*100}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TP : 6250, TN : 0, FP : 5750, FN : 0\n",
            "Precision 52.083333333333336\n",
            "Recall 100.0\n",
            "F1 Score 68.4931506849315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMsyCgziqeaa",
        "colab_type": "text"
      },
      "source": [
        "Great! At this point, you must have created a succesfful attack model that can detect whether a datapoint was used in training a target mode or not. \n",
        "* A successful attack model is one with a precision/recall higher than 85% -- you are using same architecture and are aware of the data classes\n",
        "\n",
        " \n",
        " Can you suggest any defense mechanism? If yes, Apply them to your solution and re-evaluate your attack model. How did your defense mecanism affect the accuracy of the target model? How did it affect the recall and precision of the Attack model?"
      ]
    }
  ]
}