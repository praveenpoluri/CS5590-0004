{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab Membership_Attack_solution_guidelines.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveenpoluri/CS5590-0004/blob/master/Lab2/Lab_Membership_Attack_solution_guidelines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvK6LaVhrfZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# required imports\n",
        "import sys \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision \n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O05dkTKAsEh-",
        "colab_type": "code",
        "outputId": "333d6ff7-9d5b-48c9-a2ae-64987e3e520f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# mount the google drive to download the datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "project_path = '/content/drive/My Drive/cybersecurity'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEW1mLverl7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create transforms to load the images, nothing much is needed here. \n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Normalize the test set same as training set without augmentation\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjsFJTFwr1wV",
        "colab_type": "code",
        "outputId": "3082e0a0-1265-4102-d5d0-35e44864457e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# download CIFAR 10 training set\n",
        "trainset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "\n",
        "# load the trainning set\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "\n",
        "# download the test data\n",
        "testset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=False,\n",
        "                                        download=True, transform=transform_test)\n",
        "\n",
        "# load the test data\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "# check those manually on the dataset site: https://www.cs.toronto.edu/~kriz/cifar.html"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/drive/My Drive/cybersecurity/data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:02, 71345304.81it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itY7G_y3tDnC",
        "colab_type": "code",
        "outputId": "c2ffb402-9df8-49a8-bcd4-81f685a5d85a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "# helper function to unnormalize and plot image \n",
        "def imshow(img):\n",
        "    img = np.array(img)\n",
        "    img = img / 2 + 0.5\n",
        "    img = np.moveaxis(img, 0, -1)\n",
        "    plt.imshow(img)\n",
        "    \n",
        "# display sample from dataset \n",
        "imgs, labels = iter(trainloader).next()\n",
        "imshow(torchvision.utils.make_grid(imgs)) \n",
        "\n",
        "# notice who we converted the class idx to labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "# run this cell multiple times and notice diff images"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "truck  deer  deer   dog\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqkixgwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJK32k42gbEK",
        "colab_type": "code",
        "outputId": "7dd3ec77-20f8-4888-fb8b-3363a817aa3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# divide the training dataset into the required groups Make sure they are balanced\n",
        "# original trainset is made of 50k images\n",
        "\n",
        "total_size = len(trainset)\n",
        "split1 = total_size // 4\n",
        "split2 = split1 * 2\n",
        "split3 = split1 * 3\n",
        "\n",
        "print(total_size, split1, split2, split3)\n",
        "\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "shadow_train_idx = indices[:split1]\n",
        "shadow_out_idx = indices[split1:split2]\n",
        "\n",
        "# two groups to train the Target (in and out)\n",
        "target_train_idx = indices[split2:split3]\n",
        "target_out_idx =  indices[split3:]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 12500 25000 37500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4wJ_0lkhp76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj9LuQJNuCXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# create a CNN\n",
        "# Input shape (3, 32, 32) \n",
        "# architecture: simple. 2 conv and 2 Max pool, followed by 2 fc (120, 84) \n",
        "# output of fc is 10 because we have 10 classes!\n",
        "\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        \n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "        \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O39H-xzClPgh",
        "colab_type": "code",
        "outputId": "48418541-c22b-4ff2-9ec2-18f54c614f2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# check if CUDA available or not\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER_B4V8YjKyU",
        "colab_type": "code",
        "outputId": "5c63fbe4-72cd-425a-bc33-7583eb58bb47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# initalize a target model and train it\n",
        "\n",
        "target_model = CNN()\n",
        "taget_model = target_model.cuda()\n",
        "criterion = nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "optimizer = optim.Adam(target_model.parameters(), lr=0.0003) # try Adam VS SGD\n",
        "\n",
        "    \n",
        "epochs = 20\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in target_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        logits = target_model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(\"\\nEpoch : {}/{}..\".format(e+1,epochs),f\"Training loss: {running_loss/len(target_train_loader)}\")\n",
        "\n",
        "#save the model\n",
        "print(\"Model: \\n\\n\", target_model, '\\n')\n",
        "torch.save(target_model.state_dict(), project_path+'/target_checkpoint.pth')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 1/20.. Training loss: 1.7969661182759669\n",
            "\n",
            "Epoch : 2/20.. Training loss: 1.4670740907911755\n",
            "\n",
            "Epoch : 3/20.. Training loss: 1.279429255429741\n",
            "\n",
            "Epoch : 4/20.. Training loss: 1.132766926227628\n",
            "\n",
            "Epoch : 5/20.. Training loss: 1.0318320096682405\n",
            "\n",
            "Epoch : 6/20.. Training loss: 0.933371312935334\n",
            "\n",
            "Epoch : 7/20.. Training loss: 0.8640352388858186\n",
            "\n",
            "Epoch : 8/20.. Training loss: 0.808357906272954\n",
            "\n",
            "Epoch : 9/20.. Training loss: 0.7637845044360136\n",
            "\n",
            "Epoch : 10/20.. Training loss: 0.7210876525324934\n",
            "\n",
            "Epoch : 11/20.. Training loss: 0.6847510942450875\n",
            "\n",
            "Epoch : 12/20.. Training loss: 0.646618084901053\n",
            "\n",
            "Epoch : 13/20.. Training loss: 0.6238846240369865\n",
            "\n",
            "Epoch : 14/20.. Training loss: 0.584842486683365\n",
            "\n",
            "Epoch : 15/20.. Training loss: 0.5544655366593501\n",
            "\n",
            "Epoch : 16/20.. Training loss: 0.5264931185852231\n",
            "\n",
            "Epoch : 17/20.. Training loss: 0.5170178238178611\n",
            "\n",
            "Epoch : 18/20.. Training loss: 0.4784246765629715\n",
            "\n",
            "Epoch : 19/20.. Training loss: 0.4570714529041591\n",
            "\n",
            "Epoch : 20/20.. Training loss: 0.4450615149448671\n",
            "Model: \n",
            "\n",
            " CNN(\n",
            "  (conv_layer): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Dropout2d(p=0.05)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Dropout(p=0.1)\n",
            "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.1)\n",
            "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (7): LogSoftmax()\n",
            "  )\n",
            ") \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpY8ktdskRQN",
        "colab_type": "code",
        "outputId": "6d545d73-596f-4431-83a6-79903d1752a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the accuracy of the Target Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = target_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 12500 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 76 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEClKFqikmUl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha_VqRVVkoCm",
        "colab_type": "code",
        "outputId": "ebbceb85-f43f-40db-fee2-b24bb114d9c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# initalize a Shadow Model and Train it\n",
        "# for the first ICP, your shadow model can have the same CNN architecture and hyperparameters\n",
        "\n",
        "shadow_model = CNN()\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()\n",
        "#send to GPU\n",
        "shadow_model = shadow_model.cuda()\n",
        "shadow_criterion =  nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "shadow_optimizer = optim.Adam(shadow_model.parameters(), lr=0.0003) # ADAM \n",
        "\n",
        "\n",
        "# let the magic begin\n",
        "epochs = 20\n",
        "with torch.set_grad_enabled(True):\n",
        "  for e in range(epochs):\n",
        "      running_loss = 0\n",
        "      for images, labels in shadow_train_loader:\n",
        "          # sending tensors to GPU\n",
        "          images = images.cuda()\n",
        "          labels = labels.cuda()\n",
        "          shadow_optimizer.zero_grad()\n",
        "          logits = shadow_model(images)\n",
        "          shadow_loss = shadow_criterion(logits, labels)\n",
        "          shadow_loss.backward()\n",
        "          shadow_optimizer.step()\n",
        "\n",
        "\n",
        "          running_loss += shadow_loss.item()\n",
        "      else:\n",
        "          print(\"\\nEpoch : {}/{}..\".format(e+1,epochs),f\"Training loss: {running_loss/len(shadow_train_loader)}\")\n",
        "\n",
        "#save the model\n",
        "print(\"Our model: \\n\\n\", shadow_model, '\\n')\n",
        "torch.save(shadow_model.state_dict(), project_path+'/shadow_checkpoint.pth')\n",
        "print('Finished Training the Shadow model')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 1/20.. Training loss: 1.8446058222399953\n",
            "\n",
            "Epoch : 2/20.. Training loss: 1.5224975480905274\n",
            "\n",
            "Epoch : 3/20.. Training loss: 1.3317037403126202\n",
            "\n",
            "Epoch : 4/20.. Training loss: 1.1857584659629465\n",
            "\n",
            "Epoch : 5/20.. Training loss: 1.0837630411548078\n",
            "\n",
            "Epoch : 6/20.. Training loss: 0.9983621288062362\n",
            "\n",
            "Epoch : 7/20.. Training loss: 0.9223012272697275\n",
            "\n",
            "Epoch : 8/20.. Training loss: 0.8536748425734927\n",
            "\n",
            "Epoch : 9/20.. Training loss: 0.8047683985565629\n",
            "\n",
            "Epoch : 10/20.. Training loss: 0.7622472041469934\n",
            "\n",
            "Epoch : 11/20.. Training loss: 0.7221207036005567\n",
            "\n",
            "Epoch : 12/20.. Training loss: 0.6843595515812755\n",
            "\n",
            "Epoch : 13/20.. Training loss: 0.6495163613439673\n",
            "\n",
            "Epoch : 14/20.. Training loss: 0.6147862747502144\n",
            "\n",
            "Epoch : 15/20.. Training loss: 0.5964926511258878\n",
            "\n",
            "Epoch : 16/20.. Training loss: 0.5716317121768394\n",
            "\n",
            "Epoch : 17/20.. Training loss: 0.5437041014918814\n",
            "\n",
            "Epoch : 18/20.. Training loss: 0.5226977473158209\n",
            "\n",
            "Epoch : 19/20.. Training loss: 0.49706591800560274\n",
            "\n",
            "Epoch : 20/20.. Training loss: 0.4729327837534039\n",
            "Our model: \n",
            "\n",
            " CNN(\n",
            "  (conv_layer): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Dropout2d(p=0.05)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Dropout(p=0.1)\n",
            "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.1)\n",
            "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (7): LogSoftmax()\n",
            "  )\n",
            ") \n",
            "\n",
            "Finished Training the Shadow model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0kP_-62ljFE",
        "colab_type": "code",
        "outputId": "55a2090c-f679-40bd-b7d1-eba2d3eac58c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the accuracy of the Shadow Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = shadow_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        #print(predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 12500 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 75 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ymKnj7QpdDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = CNN()\n",
        "    model.load_state_dict(checkpoint)\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J1B1OhMp6er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaD8_N34l3Eh",
        "colab_type": "code",
        "outputId": "03603852-ffb4-4d9a-ebf0-36945692b86d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#load the model\n",
        "load_shadow_model = load_checkpoint(project_path+'/shadow_checkpoint.pth')\n",
        "load_shadow_model = load_shadow_model.cuda()\n",
        "\n",
        "#load the model\n",
        "load_shadow_model = load_checkpoint(project_path+'/shadow_checkpoint.pth')\n",
        "load_shadow_model = load_shadow_model.cuda()\n",
        "\n",
        "# freeze the Shadow model \n",
        "for param in load_shadow_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "\n",
        "labels_0 = 0#np.zeros(1)\n",
        "labels_1 = 1#np.ones(1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "print(predictions[0])  \n",
        "print(predictions[13000])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([0.00190172, 0.00212044, 0.06136394, 0.3834541 , 0.2134003 ,\n",
            "       0.12754487, 0.11648551, 0.08086601, 0.00204282, 0.01082018],\n",
            "      dtype=float32), 1]\n",
            "[array([2.4176765e-07, 1.7204570e-06, 2.6243908e-05, 3.7332732e-04,\n",
            "       3.3210862e-02, 1.4967576e-02, 4.1874820e-05, 9.5137799e-01,\n",
            "       6.1789192e-09, 7.9968672e-08], dtype=float32), 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhaKjRRUl6Po",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a new dataset of the shape [predictions(shadow_in), 1], [predicitons(shadow_out), 0] and zip them together\n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/shadow.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl56BLIpl8Nl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the recall and precision of your attack network using the Target_out and Target_in datasets\n",
        "# to do so, take a random numer of datapoints, run them throw the target model,\n",
        "#load the model\n",
        "load_target_model = load_checkpoint(project_path+'/target_checkpoint.pth')\n",
        "load_target_model = load_target_model.cuda()\n",
        "\n",
        "# freeze the Shadow model \n",
        "for param in load_target_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "label_size = (1,1)\n",
        "\n",
        "labels_0 = 0\n",
        "labels_1 = 1\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/target.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yEnRcZW6sUY",
        "colab_type": "code",
        "outputId": "f49bcc6a-aea6-4e44-a6e2-62dab91196b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# check if CUDA available or not\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UZ2tfJzl94s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/shadow.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    predictionsList = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJFbXp8umAam",
        "colab_type": "code",
        "outputId": "0d68dc85-cc26-4aa8-c4cd-1197e7b3260e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total_size = len(predictionsList)\n",
        "split1 = total_size // 4\n",
        "split1 = total_size - split1 \n",
        "split2 = split1*2\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "train_idx = indices[:] \n",
        "test_idx = indices[split1:] \n",
        "print(f'No.of train date {len(train_idx)} and No.of test data {len(test_idx)}')\n",
        "batch_size = 10 # pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "train_sampler = SubsetRandomSampler(train_idx) # Pytorch function\n",
        "train_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=train_sampler)\n",
        "\n",
        "test_sampler = SubsetRandomSampler(test_idx) # Pytorch function\n",
        "test_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=test_sampler)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No.of train date 25000 and No.of test data 6250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU012hhrmDvi",
        "colab_type": "code",
        "outputId": "857d5c49-47b7-4775-83e5-c4e9243c1369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# create the Attack Model: A NN binary classifier {0, 1}\n",
        "# the input to this model is the propability distribution vector of size 10\n",
        "# and the output is either 0 (input was not included in training) or 1\n",
        "from torch.autograd import Variable\n",
        "attack_model = nn.Sequential(nn.Linear(10, 20),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(20, 26),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(26, 16),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(16, 8),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(8, 2),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "attack_model = attack_model.cuda()\n",
        "attack_criterion = nn.CrossEntropyLoss()\n",
        "attack_optimizer = optim.Adam(attack_model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for outputs, labels in train_loader:\n",
        "        # sending tensors to GPU\n",
        "        outputs = outputs.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        attack_optimizer.zero_grad()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        #print(pred.data, labels)\n",
        "        loss = attack_criterion(pred, labels)\n",
        "        loss.backward()\n",
        "        attack_optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(predictionsList)}\")\n",
        "        \n",
        "torch.save(attack_model.state_dict(), project_path+'/attack_checkpoint.pth')\n",
        "print('Finished Training the Attack model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.06935151975631713\n",
            "Training loss: 0.06934330963373184\n",
            "Training loss: 0.06933639912128449\n",
            "Training loss: 0.06932635615348816\n",
            "Training loss: 0.06932766935825348\n",
            "Finished Training the Attack model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWR_CXQEmIC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/target.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    validation = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdzFfdRI2prR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/shadow.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    predictionsList = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecc2gaFmHnoz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99774a85-19a3-457d-f4f6-e125e25de6be"
      },
      "source": [
        "batch_size = 1 # total_size = len(predictionsList)\n",
        "split1 = total_size // 4\n",
        "split1 = total_size - split1 \n",
        "split2 = split1*2\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "train_idx = indices[:] \n",
        "test_idx = indices[split1:] \n",
        "print(f'No.of train date {len(train_idx)} and No.of test data {len(test_idx)}')\n",
        "batch_size = 10 # pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "train_sampler = SubsetRandomSampler(train_idx) # Pytorch function\n",
        "train_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=train_sampler)\n",
        "\n",
        "test_sampler = SubsetRandomSampler(test_idx) # Pytorch function\n",
        "test_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=test_sampler)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No.of train date 25000 and No.of test data 6250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haNVIg-FHsFv",
        "colab_type": "code",
        "outputId": "5035c5e3-d58d-4128-b5c3-c3088fbe1ea3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# create the Attack Model: A NN binary classifier {0, 1}\n",
        "# the input to this model is the propability distribution vector of size 10\n",
        "# and the output is either 0 (input was not included in training) or 1\n",
        "from torch.autograd import Variable\n",
        "attack_model = nn.Sequential(nn.Linear(10, 20),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(20, 26),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(26, 16),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(16, 8),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(8, 2),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "attack_model = attack_model.cuda()\n",
        "attack_criterion = nn.CrossEntropyLoss()\n",
        "attack_optimizer = optim.Adam(attack_model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for outputs, labels in train_loader:\n",
        "        # sending tensors to GPU\n",
        "        outputs = outputs.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        attack_optimizer.zero_grad()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        #print(pred.data, labels)\n",
        "        loss = attack_criterion(pred, labels)\n",
        "        loss.backward()\n",
        "        attack_optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(predictionsList)}\")\n",
        "        \n",
        "torch.save(attack_model.state_dict(), project_path+'/attack_checkpoint.pth')\n",
        "print('Finished Training the Attack model')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.06933266881942748\n",
            "Training loss: 0.06932684851646423\n",
            "Training loss: 0.06932511482238769\n",
            "Training loss: 0.06933355016231536\n",
            "Training loss: 0.06933407550573349\n",
            "Finished Training the Attack model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FDlWceY31bB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/target.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    validation = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNsjLWUx37h9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "batch_size = 1 # pick your own\n",
        "\n",
        "validation_sampler = SubsetRandomSampler(indices[6250:18250]) # randomly picking 5000 data items\n",
        "validation_loader = torch.utils.data.DataLoader(validation, batch_size=batch_size, sampler=validation_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ocTlreq4BpZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "a8c2e0cc-6760-49f6-cdeb-af1a46531166"
      },
      "source": [
        "#input the output of the target model to your attack network \n",
        "# you already know the target_in and target_out samples, so use that info to evaluate the attack model\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "total = 0\n",
        "tp = 0\n",
        "tn = 0\n",
        "fp = 0\n",
        "fn = 0\n",
        "with torch.no_grad():\n",
        "    for outputs, labels in validation_loader:\n",
        "        # sending tensors to GPU\n",
        "        outputs = outputs.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        predicted = torch.argmax(pred.data)\n",
        "        #print('\\n',pred.data, predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted.item() == labels.item())\n",
        "        tp += ((predicted.item() == labels.item()) and (predicted.item() == 1))\n",
        "        tn += ((predicted.item() == labels.item()) and (predicted.item() == 0))\n",
        "        fp += ((predicted.item() != labels.item()) and (predicted.item() == 1))\n",
        "        fn += ((predicted.item() != labels.item()) and (predicted.item() == 0))\n",
        "incorrect = total- correct\n",
        "print(f'TP : {tp}, TN : {tn}, FP : {fp}, FN : {fn}')\n",
        "if((tp+fp)!=0):\n",
        "  pre = tp/(tp+fp)\n",
        "if((tp+fn)!=0):\n",
        "  rec = tp/(tp+fn)\n",
        "print(f'Precision {pre*100}')\n",
        "print(f'Recall {rec*100}')\n",
        "print(f'F1 Score {2*((pre*rec)/(pre+rec))*100}')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TP : 6250, TN : 0, FP : 5750, FN : 0\n",
            "Precision 52.083333333333336\n",
            "Recall 100.0\n",
            "F1 Score 68.4931506849315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMsyCgziqeaa",
        "colab_type": "text"
      },
      "source": [
        "Great! At this point, you must have created a succesfful attack model that can detect whether a datapoint was used in training a target mode or not. \n",
        "* A successful attack model is one with a precision/recall higher than 85% -- you are using same architecture and are aware of the data classes\n",
        "\n",
        " \n",
        " Can you suggest any defense mechanism? If yes, Apply them to your solution and re-evaluate your attack model. How did your defense mecanism affect the accuracy of the target model? How did it affect the recall and precision of the Attack model?"
      ]
    }
  ]
}